{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paefA073dIDo",
        "outputId": "6ea5350c-e054-459f-89e1-29f3194f2064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# Now, install the dependencies\n",
        "!pip install datasets\n",
        "!pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "24a54c4b9a8348ad88dcf8a7ffeb2236",
            "d972b0a560784c4c9be9c015efe98bd0",
            "273fd53527b54bd98625fdc591261fc1",
            "dfc7abb8d2de495394ab54a5111d7455",
            "63a2915e1a0d4758a063442c0d0e304e",
            "d06203cb91784780a7cea1413794b87f",
            "2a00c554f771434cba698eab7a1cbd5c",
            "99c6a1b6ff214d0abd7689521f657a74",
            "8c363696432d42b99635ef1d4c81dfb0",
            "710b09cc61254530898488156362fcd0",
            "8019ab3b505a494ebb4154a2c56d63dd",
            "5432cc4121994387abd277f7333f7e78",
            "82e9cf491ed54be6ae470c76d87d1ebc",
            "dbf255681a8b440e8468d617b7db2790",
            "32a9c815badc441998291533f7e114be",
            "da0beb2d0d7f42138f3783a64e390355",
            "83ed0ddd19984f238b33b64a3e6376a1",
            "526f806ffd19490185fec83def0be2bf",
            "c90372920855432f91efcb8a09e21062",
            "07f6834e91a8458997795636ddcf183b"
          ]
        },
        "id": "epq50u9ZgSLR",
        "outputId": "2f09b040-fc54-4d20-ef27-169121e336e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please log in to your Hugging Face account.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24a54c4b9a8348ad88dcf8a7ffeb2236"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from huggingface_hub import notebook_login\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# --- Step 1: Login to Hugging Face ---\n",
        "# A login box will appear. Paste your Hugging Face access token here.\n",
        "# Get a token at: https://huggingface.co/settings/tokens\n",
        "print(\"Please log in to your Hugging Face account.\")\n",
        "notebook_login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414,
          "referenced_widgets": [
            "041a8aaa0405463a80ca9e79e3a8e5fa",
            "7c7eebba9138451e9f9259dd844eb69e",
            "d863f4b18a5646d19cefad9739ae5ad3",
            "d9d7b91ec95d46c8b0522943cfefce64",
            "99a130083a83458186978d802188265f",
            "3b32806f1214435183802cacbe3c1bf8",
            "693de824dffd492abb9ae78ba6d9d837",
            "54249ff9b28e41fe903b738af96c98bf",
            "e49baae21b8842fd955c09f886883f0f",
            "383a6c7db98248ba9a3a1264b2e8edc9",
            "e2d1a3873e5d4662bbd92287bd49d4c2"
          ]
        },
        "id": "VsHjmKkqeJ9Y",
        "outputId": "5bf64776-7d21-4bea-bc69-5dcbd15d6998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directory for text files: data\n",
            "Loading tokenizer for 'meta-llama/Llama-3.2-3B'...\n",
            "✅ Tokenizer loaded successfully.\n",
            "\n",
            "============================================================\n",
            "🌍 Processing language: en\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "041a8aaa0405463a80ca9e79e3a8e5fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokens for en: 1000237tok [00:05, 176553.95tok/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Saving 1002 docs (1,000,237 tokens) to data/wikipedia_1M_en.txt...\n",
            "✅ Successfully saved file for language 'en'. (1,000,237 tokens total)\n",
            "\n",
            "============================================================\n",
            "🌍 Processing language: hi\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokens for hi: 1000854tok [00:04, 238108.15tok/s]                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Saving 564 docs (1,000,854 tokens) to data/wikipedia_1M_hi.txt...\n",
            "✅ Successfully saved file for language 'hi'. (1,000,854 tokens total)\n",
            "\n",
            "🎯 All languages processed successfully with 1M tokens each!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Step 2: Configuration ---\n",
        "PROJECT_PATH = \"\"\n",
        "OUTPUT_DIR = os.path.join(PROJECT_PATH, \"data\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ✅ Collect ~1 million tokens per language\n",
        "TARGET_TOKEN_COUNT = 1_000_000\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B\"\n",
        "LANGUAGES = ['en', 'hi']\n",
        "CONFIG_DATE = '20231101'\n",
        "\n",
        "print(f\"Output directory for text files: {OUTPUT_DIR}\")\n",
        "\n",
        "# --- Step 3: Load the Tokenizer ---\n",
        "print(f\"Loading tokenizer for '{MODEL_NAME}'...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "print(\"✅ Tokenizer loaded successfully.\")\n",
        "\n",
        "# --- Step 4: Process each language ---\n",
        "for lang in LANGUAGES:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"🌍 Processing language: {lang}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    collected_documents = []\n",
        "    current_token_count = 0\n",
        "\n",
        "    dataset_config = f\"{CONFIG_DATE}.{lang}\"\n",
        "    streaming_dataset = load_dataset(\n",
        "        'wikimedia/wikipedia',\n",
        "        dataset_config,\n",
        "        split='train',\n",
        "        streaming=True\n",
        "    )\n",
        "\n",
        "    pbar = tqdm(desc=f\"Tokens for {lang}\", total=TARGET_TOKEN_COUNT, unit='tok')\n",
        "\n",
        "    for doc in streaming_dataset:\n",
        "        if current_token_count >= TARGET_TOKEN_COUNT:\n",
        "            break\n",
        "\n",
        "        text = doc.get('text', '')\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        # ⚡ Optional: truncate very large docs for efficiency\n",
        "        text = text[:5000]\n",
        "        num_tokens = len(tokenizer.encode(text, add_special_tokens=False))\n",
        "\n",
        "        if num_tokens == 0:\n",
        "            continue\n",
        "\n",
        "        collected_documents.append(text)\n",
        "        current_token_count += num_tokens\n",
        "        pbar.update(num_tokens)\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    # --- Step 5: Save to file ---\n",
        "    output_filepath = os.path.join(OUTPUT_DIR, f\"wikipedia_1M_{lang}.txt\")\n",
        "    print(f\"\\n💾 Saving {len(collected_documents)} docs ({current_token_count:,} tokens) to {output_filepath}...\")\n",
        "\n",
        "    with open(output_filepath, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"\\n\\n\".join(collected_documents))\n",
        "\n",
        "    print(f\"✅ Successfully saved file for language '{lang}'. ({current_token_count:,} tokens total)\")\n",
        "\n",
        "print(\"\\n🎯 All languages processed successfully with 1M tokens each!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498,
          "referenced_widgets": [
            "9a589bb4fbc34a35966fe0ef329f9750",
            "acc219b182b3400aa60c3fa7e81e2d4a",
            "d61dfd854c3b4b8991b96979ab9e991b",
            "148aa7658ca9420bbecaf3352f95ac19",
            "05598cc09e0c40a8be93265aba042a68",
            "dc0b2c5a23a149bf8d7b3ca3d2bb8cb9",
            "a5128e72222b4f0ea09d694ce812cea5",
            "0509a20679de4e2c810c3ab11da3dcd0",
            "14dc03457b724bca8a19a0ef8dc8ac8b",
            "e6b8d0123549442dbd65c7afb0ba6bb0",
            "e84d9dc3c19f49078f00ccccbae9e8ef",
            "0ffe5ec032b84f339c2e6e3bbfbdd00a",
            "06dded1484914aa2b85183f09e05564a",
            "60dc3594bae64d5d87f515d40cd6ec68",
            "3431a7399cc641578e92a459d31dca52",
            "4ef32b90ddf64fdda32be53307bffb59",
            "98db2e0480a64e16a64033c556870974",
            "964a0696923d4a98915f520c0167fd07",
            "b6be5aa92ebe40d69170ca0747bb57c3",
            "1a5a80caffba48db95fa4b86c841ed13",
            "2ccc65d1f06c4b269644ea56f420271d",
            "e519a560fc1c413ebff0c30fe0cb298d"
          ]
        },
        "id": "3fQeTisR7G7D",
        "outputId": "e86d4f4a-85b2-4ce2-cf62-678796b821c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Loading tokenizer...\n",
            "✅ Tokenizer loaded successfully.\n",
            "\n",
            "======================================================================\n",
            "🌍 Processing language: en\n",
            "📥 Reading from: data/wikipedia_1M_en.txt\n",
            "💾 Saving to: data/id.en.1M.llama.pt\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing en: 0line [00:00, ?line/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a589bb4fbc34a35966fe0ef329f9750"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌀 Flushed 500,048 tokens to data/id.en.1M.llama.pt\n",
            "✅ Final flush: saved 491,293 remaining tokens\n",
            "✅ Token tensor for 'en' saved successfully.\n",
            "📊 Total tokens processed: 991,341\n",
            "\n",
            "======================================================================\n",
            "🌍 Processing language: hi\n",
            "📥 Reading from: data/wikipedia_1M_hi.txt\n",
            "💾 Saving to: data/id.hi.1M.llama.pt\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing hi: 0line [00:00, ?line/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ffe5ec032b84f339c2e6e3bbfbdd00a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌀 Flushed 500,025 tokens to data/id.hi.1M.llama.pt\n",
            "✅ Final flush: saved 494,521 remaining tokens\n",
            "✅ Token tensor for 'hi' saved successfully.\n",
            "📊 Total tokens processed: 994,546\n",
            "\n",
            "🎯 All tokenization steps complete for 1M-token datasets!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# --- Configuration ---\n",
        "PROJECT_PATH = \"\"\n",
        "DATA_DIR = os.path.join(PROJECT_PATH, \"data\")\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B\"\n",
        "LANGUAGES = ['en', 'hi']\n",
        "\n",
        "print(\"🔹 Loading tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "print(\"✅ Tokenizer loaded successfully.\")\n",
        "\n",
        "# --- Tokenize each 1M-token dataset ---\n",
        "for lang in LANGUAGES:\n",
        "    input_filepath = os.path.join(DATA_DIR, f\"wikipedia_1M_{lang}.txt\")\n",
        "    output_filepath = os.path.join(DATA_DIR, f\"id.{lang}.1M.llama.pt\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"🌍 Processing language: {lang}\")\n",
        "    print(f\"📥 Reading from: {input_filepath}\")\n",
        "    print(f\"💾 Saving to: {output_filepath}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    if not os.path.exists(input_filepath):\n",
        "        print(f\"❌ ERROR: Input file not found at {input_filepath}\")\n",
        "        continue\n",
        "\n",
        "    token_ids = []\n",
        "    total_tokens = 0\n",
        "    flush_interval = 500_000  # flush every 0.5M tokens\n",
        "\n",
        "    with open(input_filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in tqdm(f, desc=f\"Tokenizing {lang}\", unit=\"line\"):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Encode text into token IDs\n",
        "            ids = tokenizer.encode(line, add_special_tokens=False)\n",
        "            if not ids:\n",
        "                continue\n",
        "\n",
        "            token_ids.extend(ids)\n",
        "            total_tokens += len(ids)\n",
        "\n",
        "            # Periodically flush to disk to prevent memory overflow\n",
        "            if len(token_ids) >= flush_interval:\n",
        "                torch.save(torch.LongTensor(token_ids), output_filepath)\n",
        "                print(f\"🌀 Flushed {len(token_ids):,} tokens to {output_filepath}\")\n",
        "                token_ids = []\n",
        "\n",
        "    # --- Save remaining tokens ---\n",
        "    if token_ids:\n",
        "        torch.save(torch.LongTensor(token_ids), output_filepath)\n",
        "        print(f\"✅ Final flush: saved {len(token_ids):,} remaining tokens\")\n",
        "\n",
        "    print(f\"✅ Token tensor for '{lang}' saved successfully.\")\n",
        "    print(f\"📊 Total tokens processed: {total_tokens:,}\")\n",
        "\n",
        "print(\"\\n🎯 All tokenization steps complete for 1M-token datasets!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_DIR = \"data\"  # folder containing your original 1M-token files\n",
        "LANGUAGES = [\"en\", \"hi\"]\n",
        "VALIDATION_RATIO = 0.05  # 5% of tokens for validation\n",
        "\n",
        "# Loop over each language\n",
        "for lang in LANGUAGES:\n",
        "    # Original training file (1M tokens)\n",
        "    train_path = os.path.join(DATA_DIR, f\"id.{lang}.train.1M.llama.pt\")\n",
        "\n",
        "    if not os.path.exists(train_path):\n",
        "        print(f\"❌ File not found: {train_path}\")\n",
        "        continue\n",
        "\n",
        "    # Load the full training token tensor\n",
        "    all_tokens = torch.load(train_path)\n",
        "    total_tokens = all_tokens.size(0)\n",
        "\n",
        "    # Compute sizes\n",
        "    val_size = int(total_tokens * VALIDATION_RATIO)\n",
        "    train_size = total_tokens - val_size\n",
        "\n",
        "    # Split tokens into train and validation\n",
        "    train_tokens = all_tokens[:train_size]\n",
        "    valid_tokens = all_tokens[train_size:]\n",
        "\n",
        "    # Save new train and validation files\n",
        "    train_out = os.path.join(DATA_DIR, f\"id.{lang}.train.1M.llama.pt\")\n",
        "    valid_out = os.path.join(DATA_DIR, f\"id.{lang}.valid.1M.llama.pt\")\n",
        "\n",
        "    torch.save(train_tokens, train_out)\n",
        "    torch.save(valid_tokens, valid_out)\n",
        "\n",
        "    print(f\"✅ {lang.upper()} split:\")\n",
        "    print(f\"   Train tokens: {train_size} → {train_out}\")\n",
        "    print(f\"   Validation tokens: {val_size} → {valid_out}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CLxmo5ChyE_",
        "outputId": "cb9aaf43-46c9-47e2-b8a5-77bc72144186"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ EN split:\n",
            "   Train tokens: 443393 → data/id.en.train.1M.llama.pt\n",
            "   Validation tokens: 23336 → data/id.en.valid.1M.llama.pt\n",
            "✅ HI split:\n",
            "   Train tokens: 446306 → data/id.hi.train.1M.llama.pt\n",
            "   Validation tokens: 23489 → data/id.hi.valid.1M.llama.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m_FuYyP9PdA"
      },
      "source": [
        "**activation.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Sj9gYwNLy-dt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445,
          "referenced_widgets": [
            "60c705976808428591889b82a68c215f",
            "18d62d688b604be78e9365a54e3ec2ed",
            "0faf9044659e4427a94b2d7a1aebdfd2",
            "087c289b7f4440e39c4ca9d5c110a98a",
            "2588bd2416414005953bef245afbfa66",
            "9a6a48918afc436f852da80c416b3cd0",
            "23a887eeaea94318b3eaf078857c7332",
            "621b34ea0cf04cab9fd3db2477fff8d9",
            "75c0bd51b74041e09d78f5d288ae4082",
            "b7a97815f6934a878b90825652dacaa0",
            "c977a95a59d54b618d8a2e71d3cb634c",
            "0c8a67f65f3d43afa449e67a54c09e64",
            "b0a5ec90e84a4a79a7988bd7d332c896",
            "789af59404404a29816432fad5b654e9",
            "f3d6d18b1f9d4eaa879e860599d8293f",
            "0a76234ade4046c7b63cb3be45bef91c",
            "508a66609d874233b77585a1b7672cb9",
            "15486604610449a79040d8c5fcd56158",
            "5448848d76a546bf869546eda767e8da",
            "65c8496c9669406aaae7e836211848ce",
            "2397e1aea68544e8877da237d6f58b25",
            "dd90de49463146c3a29befd6f5d02613",
            "b699254e3a87438eaffed7ac304b5f96",
            "6d9bf87aca664665998e6a912192a71d",
            "3b1ce9b60bc14529bd73d10ab10d7e99",
            "470b782e4c704fe2a64819f23c68ec62",
            "77e0baf0ffb34c2bb5902ea63a1c91b9",
            "e99c549e2f85402fb8335a2793ba55c7",
            "c0fa37d409a94466a7f180593a249134",
            "1f7191fabb094b9698b93eec1316541e",
            "0e7ae510f5f0482481c8fcab74e8c2c6",
            "7447eb94fc5f4272836d0e52e06563e3",
            "06f25031932f4b189325a2f194ad81a0"
          ]
        },
        "outputId": "5ecbcdd6-3fbb-4a0a-a2cf-5be797a14f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Loading model and tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60c705976808428591889b82a68c215f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully.\n",
            "📊 Model has 28 layers, intermediate size = 8192\n",
            "\n",
            "🌍 Processing language: en (443,393 tokens)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "🔄 Forward passes for en:   0%|          | 0/217 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c8a67f65f3d43afa449e67a54c09e64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved activations for 'en' → data/activation.en.train.1M.llama3b.pt\n",
            "\n",
            "🌍 Processing language: hi (446,306 tokens)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "🔄 Forward passes for hi:   0%|          | 0/218 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b699254e3a87438eaffed7ac304b5f96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved activations for 'hi' → data/activation.hi.train.1M.llama3b.pt\n",
            "\n",
            "🎯 Activation collection completed for all languages (1M-token datasets).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B\"\n",
        "LANGUAGES = ['en', 'hi']\n",
        "DATA_DIR = \"data\"\n",
        "BATCH_SIZE = 2\n",
        "MAX_LENGTH = 1024\n",
        "\n",
        "print(\"🔹 Loading model and tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "model.eval()\n",
        "print(\"✅ Model loaded successfully.\")\n",
        "\n",
        "# --- Extract model dimensions ---\n",
        "num_layers = model.config.num_hidden_layers\n",
        "intermediate_size = model.config.intermediate_size  # e.g. 8192\n",
        "print(f\"📊 Model has {num_layers} layers, intermediate size = {intermediate_size}\")\n",
        "\n",
        "# --- Initialize neuron activation counter ---\n",
        "over_zero = torch.zeros(num_layers, intermediate_size, dtype=torch.int32, device='cuda')\n",
        "\n",
        "# --- Hook for MLP activation tracking ---\n",
        "def mlp_hook(layer_idx):\n",
        "    def hook(module, input, output):\n",
        "        # Compute full activation before down projection\n",
        "        x = input[0]\n",
        "        gate_up = module.gate_proj(x)\n",
        "        up = module.up_proj(x)\n",
        "        activation = (torch.nn.functional.silu(gate_up) * up).float()\n",
        "        # Count how many activations > 0 per neuron\n",
        "        over_zero[layer_idx, :activation.size(-1)] += (activation > 0).sum(dim=(0, 1))\n",
        "    return hook\n",
        "\n",
        "# Register hooks for all MLP layers\n",
        "for i, layer in enumerate(model.model.layers):\n",
        "    layer.mlp.register_forward_hook(mlp_hook(i))\n",
        "\n",
        "# --- Process each language ---\n",
        "for lang in LANGUAGES:\n",
        "    tensor_path = os.path.join(DATA_DIR, f\"id.{lang}.train.1M.llama.pt\")\n",
        "    if not os.path.exists(tensor_path):\n",
        "        print(f\"❌ ERROR: Token file not found at {tensor_path}\")\n",
        "        continue\n",
        "\n",
        "    ids = torch.load(tensor_path).to('cuda')\n",
        "    total_tokens = ids.size(0)\n",
        "    print(f\"\\n🌍 Processing language: {lang} ({total_tokens:,} tokens)\")\n",
        "\n",
        "    # Process tokens in batches\n",
        "    for start in tqdm(range(0, total_tokens, BATCH_SIZE * MAX_LENGTH), desc=f\"🔄 Forward passes for {lang}\"):\n",
        "        batch_ids = []\n",
        "        for b in range(BATCH_SIZE):\n",
        "            s = start + b * MAX_LENGTH\n",
        "            if s >= total_tokens:\n",
        "                break\n",
        "            e = min(s + MAX_LENGTH, total_tokens)\n",
        "            chunk = ids[s:e]\n",
        "            if chunk.size(0) < MAX_LENGTH:\n",
        "                # Pad to full length\n",
        "                pad = torch.zeros(MAX_LENGTH - chunk.size(0), dtype=chunk.dtype, device='cuda')\n",
        "                chunk = torch.cat([chunk, pad])\n",
        "            batch_ids.append(chunk)\n",
        "\n",
        "        if not batch_ids:\n",
        "            continue\n",
        "\n",
        "        batch_ids = torch.stack(batch_ids, dim=0)\n",
        "        attention_mask = (batch_ids != 0).long()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            _ = model(input_ids=batch_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # --- Save activation statistics ---\n",
        "    output_path = os.path.join(DATA_DIR, f\"activation.{lang}.train.1M.llama3b.pt\")\n",
        "    torch.save({'over_zero': over_zero.cpu()}, output_path)\n",
        "    print(f\"✅ Saved activations for '{lang}' → {output_path}\")\n",
        "\n",
        "print(\"\\n🎯 Activation collection completed for all languages (1M-token datasets).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0V-kQUfCaDW",
        "outputId": "9d1f25ad-1dfb-4af6-cea8-58fd00ee8ffb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tensor from: data/activation.hi.train.1M.llama3b.pt\n",
            "✅ Loaded 'over_zero' tensor with shape: (28, 8192)\n",
            "\n",
            "🔹 Tensor Summary:\n",
            "Shape: (28, 8192)\n",
            "Min: 0, Max: 890880, Mean: 445263.85991123744\n",
            "\n",
            "🔹 Sample (first 3 rows):\n",
            "[[435993 436378 434422 ... 329206 424425 438842]\n",
            " [457913 449732 440073 ... 308689 436481 321708]\n",
            " [477596 431045 451697 ... 448848 457595 498834]]\n",
            "\n",
            "✅ over_zero tensor successfully saved to CSV:\n",
            "📂 data/activation.hi.train.1M.llama3b.csv\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# --- File path ---\n",
        "file_path = 'data/activation.hi.train.1M.llama3b.pt'\n",
        "\n",
        "# --- Load the .pt file ---\n",
        "print(f\"Loading tensor from: {file_path}\")\n",
        "data = torch.load(file_path, map_location='cpu')\n",
        "\n",
        "# --- Extract the 'over_zero' tensor ---\n",
        "if 'over_zero' not in data:\n",
        "    raise KeyError(\"❌ Key 'over_zero' not found in the loaded file. Available keys: \" + str(list(data.keys())))\n",
        "\n",
        "over_zero = data['over_zero'].cpu()  # Expected shape: 28 x 8192\n",
        "print(f\"✅ Loaded 'over_zero' tensor with shape: {tuple(over_zero.shape)}\")\n",
        "\n",
        "# --- Convert to NumPy for easier handling ---\n",
        "matrix = over_zero.numpy()\n",
        "\n",
        "# --- Show summary to avoid console flooding ---\n",
        "print(\"\\n🔹 Tensor Summary:\")\n",
        "print(f\"Shape: {matrix.shape}\")\n",
        "print(f\"Min: {matrix.min()}, Max: {matrix.max()}, Mean: {matrix.mean()}\")\n",
        "print(\"\\n🔹 Sample (first 3 rows):\")\n",
        "print(matrix[:3])  # print only first 3 rows for readability\n",
        "\n",
        "# --- Save to CSV ---\n",
        "csv_path = file_path.replace(\".pt\", \".csv\")\n",
        "os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
        "df = pd.DataFrame(matrix)\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"\\n✅ over_zero tensor successfully saved to CSV:\")\n",
        "print(f\"📂 {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- File path ---\n",
        "file_path = 'data/activation.en.train.1M.llama3b.pt'\n",
        "\n",
        "# --- Load the .pt file ---\n",
        "print(f\"Loading tensor from: {file_path}\")\n",
        "data = torch.load(file_path, map_location='cpu')\n",
        "\n",
        "# --- Extract the 'over_zero' tensor ---\n",
        "if 'over_zero' not in data:\n",
        "    raise KeyError(\"❌ Key 'over_zero' not found in the loaded file. Available keys: \" + str(list(data.keys())))\n",
        "\n",
        "over_zero = data['over_zero'].cpu()  # Expected shape: 28 x 8192\n",
        "print(f\"✅ Loaded 'over_zero' tensor with shape: {tuple(over_zero.shape)}\")\n",
        "\n",
        "# --- Convert to NumPy for easier handling ---\n",
        "matrix = over_zero.numpy()\n",
        "\n",
        "# --- Show summary to avoid console flooding ---\n",
        "print(\"\\n🔹 Tensor Summary:\")\n",
        "print(f\"Shape: {matrix.shape}\")\n",
        "print(f\"Min: {matrix.min()}, Max: {matrix.max()}, Mean: {matrix.mean()}\")\n",
        "print(\"\\n🔹 Sample (first 3 rows):\")\n",
        "print(matrix[:3])  # print only first 3 rows for readability\n",
        "\n",
        "# --- Save to CSV ---\n",
        "csv_path = file_path.replace(\".pt\", \".csv\")\n",
        "os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
        "df = pd.DataFrame(matrix)\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"\\n✅ over_zero tensor successfully saved to CSV:\")\n",
        "print(f\"📂 {csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qgc9CtuRWtco",
        "outputId": "7f4c54d6-f10f-4a71-e8bf-722587c6f148"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tensor from: data/activation.en.train.1M.llama3b.pt\n",
            "✅ Loaded 'over_zero' tensor with shape: (28, 8192)\n",
            "\n",
            "🔹 Tensor Summary:\n",
            "Shape: (28, 8192)\n",
            "Min: 0, Max: 444416, Mean: 222106.46555873327\n",
            "\n",
            "🔹 Sample (first 3 rows):\n",
            "[[213640 237007 202883 ... 164857 214296 238791]\n",
            " [236456 215944 212300 ... 131038 216587 139884]\n",
            " [231557 228562 232253 ... 220941 218247 229130]]\n",
            "\n",
            "✅ over_zero tensor successfully saved to CSV:\n",
            "📂 data/activation.en.train.1M.llama3b.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcEQNPhi5umt"
      },
      "source": [
        "**identify.py**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDg3o2FBPI0p",
        "outputId": "a4a0ad18-2e43-4687-eeef-f4f6ced5cf09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 languages, 28 layers, 8192 neurons per layer\n",
            "\n",
            "🔍 Top 1% language dominance based on entropy:\n",
            "    EN: 0 neurons (0.00%)\n",
            "    HI: 2294 neurons (100.00%)\n",
            "✅ Activation mask for en saved to: activation_mask/llama3b_en_mask.pt\n",
            "✅ Activation mask for hi saved to: activation_mask/llama3b_hi_mask.pt\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "languages = ['en', 'hi']  # your hi-en dataset\n",
        "activation_dir = 'data'\n",
        "output_dir = 'activation_mask'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "top_rate = 0.01           # fraction of neurons to select (entropy-based)\n",
        "filter_rate = 0.95        # top 5% neurons threshold\n",
        "activation_bar_ratio = 0.95  # top 5% activation threshold\n",
        "\n",
        "# --- Load activation data ---\n",
        "over_zero = []\n",
        "for lang in languages:\n",
        "    file_path = os.path.join(activation_dir, f'activation.{lang}.train.1M.llama3b.pt')\n",
        "    data = torch.load(file_path)\n",
        "    over_zero.append(data['over_zero'])\n",
        "\n",
        "# shape: [layers, neurons, languages]\n",
        "over_zero = torch.stack(over_zero, dim=-1)\n",
        "num_layers, intermediate_size, lang_num = over_zero.size()\n",
        "print(f\"{lang_num} languages, {num_layers} layers, {intermediate_size} neurons per layer\")\n",
        "\n",
        "# --- Compute activation probabilities across languages ---\n",
        "activation_probs = over_zero / over_zero.sum(dim=-1, keepdim=True)\n",
        "activation_probs[torch.isnan(activation_probs)] = 0\n",
        "\n",
        "# --- Compute entropy across languages ---\n",
        "log_probs = torch.where(activation_probs > 0, activation_probs.log(), 0)\n",
        "entropy = -torch.sum(activation_probs * log_probs, dim=-1)  # shape: [layers, neurons]\n",
        "\n",
        "# --- Filter neurons with very low activation ---\n",
        "flattened_probs = activation_probs.flatten()\n",
        "top_prob_value = flattened_probs.kthvalue(round(len(flattened_probs) * filter_rate)).values.item()\n",
        "active_neurons = (activation_probs > top_prob_value).sum(dim=-1)\n",
        "entropy[active_neurons == 0] = torch.inf  # ignore inactive neurons\n",
        "\n",
        "# --- Select top neurons by smallest entropy (language-specific) ---\n",
        "flattened_entropy = entropy.flatten()\n",
        "top_entropy_count = round(len(flattened_entropy) * top_rate)\n",
        "entropy_values, index = flattened_entropy.topk(top_entropy_count, largest=False)  # smallest entropy = language-specific\n",
        "\n",
        "row_index = index // entropy.size(1)\n",
        "col_index = index % entropy.size(1)\n",
        "\n",
        "# --- Determine which language dominates each top neuron ---\n",
        "# For each selected neuron (layer,row_index,col_index),\n",
        "# check which language has the higher activation probability\n",
        "dominant_lang = []\n",
        "for r, c in zip(row_index.tolist(), col_index.tolist()):\n",
        "    probs = activation_probs[r, c]  # shape [languages]\n",
        "    winner = probs.argmax().item()  # 0 -> en, 1 -> hi\n",
        "    dominant_lang.append(winner)\n",
        "\n",
        "dominant_lang = torch.tensor(dominant_lang)\n",
        "counts = torch.bincount(dominant_lang, minlength=len(languages))\n",
        "\n",
        "total = counts.sum().item()\n",
        "print(\"\\n🔍 Top 1% language dominance based on entropy:\")\n",
        "for i, lang in enumerate(languages):\n",
        "    pct = 100 * counts[i].item() / total if total > 0 else 0\n",
        "    print(f\"   {lang.upper():>3}: {counts[i].item()} neurons ({pct:.2f}%)\")\n",
        "\n",
        "# --- Build and save per-language masks separately (same as before) ---\n",
        "for lang_id, lang_name in enumerate(languages):\n",
        "    lang_probs = activation_probs[:, :, lang_id]\n",
        "    selected_mask = torch.zeros_like(lang_probs, dtype=torch.bool)\n",
        "    selected_mask[row_index, col_index] = True\n",
        "    activation_bar = flattened_probs.kthvalue(round(len(flattened_probs) * activation_bar_ratio)).values.item()\n",
        "    selected_mask &= (lang_probs > activation_bar)\n",
        "\n",
        "    layer_indices = []\n",
        "    for layer in range(num_layers):\n",
        "        neurons = torch.where(selected_mask[layer])[0]\n",
        "        layer_indices.append(neurons)\n",
        "\n",
        "    output_file = os.path.join(output_dir, f\"llama3b_{lang_name}_mask.pt\")\n",
        "    torch.save(layer_indices, output_file)\n",
        "    print(f\"✅ Activation mask for {lang_name} saved to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVLA6_dO68zO",
        "outputId": "2ff9b637-a255-4087-930b-cb8e333b0508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Activation mask for EN ---\n",
            "layer-wise neuron indices = [\n",
            "    layer 0: tensor([])\n",
            "    layer 1: tensor([])\n",
            "    layer 2: tensor([])\n",
            "    layer 3: tensor([])\n",
            "    layer 4: tensor([])\n",
            "    layer 5: tensor([])\n",
            "    layer 6: tensor([])\n",
            "    layer 7: tensor([])\n",
            "    layer 8: tensor([])\n",
            "    layer 9: tensor([])\n",
            "    layer 10: tensor([])\n",
            "    layer 11: tensor([])\n",
            "    layer 12: tensor([])\n",
            "    layer 13: tensor([])\n",
            "    layer 14: tensor([])\n",
            "    layer 15: tensor([])\n",
            "    layer 16: tensor([])\n",
            "    layer 17: tensor([])\n",
            "    layer 18: tensor([])\n",
            "    layer 19: tensor([])\n",
            "    layer 20: tensor([])\n",
            "    layer 21: tensor([])\n",
            "    layer 22: tensor([])\n",
            "    layer 23: tensor([])\n",
            "    layer 24: tensor([])\n",
            "    layer 25: tensor([])\n",
            "    layer 26: tensor([])\n",
            "    layer 27: tensor([])\n",
            "]\n",
            "\n",
            "\n",
            "--- Activation mask for HI ---\n",
            "layer-wise neuron indices = [\n",
            "    layer 0: tensor([268, 513, 988, 1365, 1652, 1934, 2353, 2788, 2815, 2990, 3451, 3936, 4278, 5281, 5758, 5943, 6197, 6237, 6248, 6384, 7374, 7503, 8004])\n",
            "    layer 1: tensor([46, 467, 806, 909, 1602, 2114, 2128, 2148, 2169, 3293, 4891, 5036, 5052, 5352, 5460, 5464, 7222, 7297])\n",
            "    layer 2: tensor([578, 1301, 1529, 1692, 2115, 2391, 2679, 2796, 2905, 2967, 3493, 5882, 6670, 7775])\n",
            "    layer 3: tensor([716, 779, 1275, 2142, 2621, 2976, 3592, 3813, 3832, 4276, 4456, 5231, 5439, 5966, 7352, 8067, 8146, 8182])\n",
            "    layer 4: tensor([317, 1421, 1526, 1823, 1827, 2025, 2265, 3302, 3338, 3615, 3849, 3996, 4107, 4668, 5738, 6244, 6281, 6659, 6919, 7045, 7099, 7155, 7219, 7552, 7559, 7579, 8005, 8083])\n",
            "    layer 5: tensor([749, 1458, 1916, 1970, 2013, 2595, 2724, 2955, 4030, 4620, 4690, 5286, 5319, 5338, 5342, 5656, 5883, 6754, 6765, 6853, 7734])\n",
            "    layer 6: tensor([231, 275, 733, 970, 1027, 1246, 1473, 1503, 1579, 2034, 3276, 3597, 3962, 5840, 5874, 6075, 6256, 6463, 6917, 7150, 7928])\n",
            "    layer 7: tensor([1466, 1480, 1740, 1904, 2063, 3230, 3328, 3337, 4593, 4891, 5532, 5883, 5896, 6877, 7014, 7083, 7197, 7499])\n",
            "    layer 8: tensor([258, 649, 754, 1811, 1895, 2834, 3492, 3734, 3951, 4129, 4679, 4766, 5104, 5436, 5620, 6246, 6580, 6661, 6772, 7356, 7944])\n",
            "    layer 9: tensor([122, 239, 453, 468, 722, 731, 1169, 1233, 1679, 2027, 2198, 2697, 2733, 2740, 2791, 2844, 3020, 3092, 3131, 3169, 3518, 3563, 3795, 4252, 4298, 4419, 4546, 4665, 4818, 4870, 5123, 5134, 5402, 5548, 5622, 5668, 5823, 5868, 6043, 6226, 6358, 6378, 6430, 6577, 6919, 7062, 7321, 7347, 7419, 7546, 7982])\n",
            "    layer 10: tensor([122, 149, 221, 501, 706, 792, 798, 1107, 1479, 1958, 2227, 2313, 2353, 2379, 2474, 2527, 2716, 2809, 2882, 3087, 3154, 3346, 4033, 4166, 4212, 4256, 4550, 4562, 4694, 4747, 4837, 4914, 5208, 5336, 5660, 6461, 6528, 6596, 6679, 7019, 7145, 7188, 7642, 7659, 7778, 7957, 8006, 8081, 8090])\n",
            "    layer 11: tensor([97, 365, 746, 910, 922, 1691, 2291, 2349, 2492, 2833, 3825, 4143, 4909, 5193, 5457, 6582, 6843, 7484])\n",
            "    layer 12: tensor([12, 121, 745, 899, 916, 1257, 1319, 1366, 1387, 1457, 1603, 1780, 1872, 2402, 2516, 2524, 3596, 3833, 3870, 3975, 3981, 3989, 4336, 4659, 4752, 5190, 5336, 5560, 5803, 5870, 5955, 6284, 6577, 6623, 7291, 7609, 7785, 7996])\n",
            "    layer 13: tensor([24, 51, 812, 965, 1196, 1390, 1414, 1535, 1578, 1997, 2143, 2166, 2284, 2378, 2533, 2534, 2544, 2735, 2814, 2996, 3097, 3348, 3461, 3582, 3651, 3679, 3878, 3895, 4106, 4482, 4490, 4664, 4709, 5130, 5226, 5272, 5313, 5633, 6051, 6346, 6432, 6530, 6575, 6812, 6820, 6959, 7041, 7230, 7262, 7287, 7351, 7423, 7532, 7623, 7819, 7921, 8146, 8188])\n",
            "    layer 14: tensor([79, 397, 574, 831, 988, 993, 1055, 1221, 1235, 1291, 1456, 1579, 1596, 1880, 1951, 2010, 2123, 2277, 2609, 2642, 2735, 2957, 2971, 3007, 3074, 3162, 3326, 3519, 3567, 3607, 3613, 3751, 3883, 3936, 3937, 3966, 4112, 4117, 4339, 4360, 4415, 4438, 4582, 5076, 5137, 5140, 5388, 5398, 5408, 5423, 5526, 5549, 5751, 5753, 5761, 5964, 6018, 6043, 6152, 6169, 6182, 6226, 6305, 6317, 6379, 6559, 6647, 6705, 6897, 7211, 7223, 7354, 7394, 7402, 7475, 7625, 7781, 7814, 7865, 8061])\n",
            "    layer 15: tensor([19, 26, 28, 82, 92, 145, 155, 177, 185, 262, 280, 294, 297, 528, 542, 659, 802, 806, 813, 863, 897, 1023, 1199, 1247, 1273, 1310, 1330, 1392, 1446, 1565, 1632, 1646, 1692, 1781, 1843, 1931, 1935, 2091, 2121, 2268, 2284, 2309, 2339, 2341, 2376, 2393, 2426, 2529, 2548, 2588, 2603, 2659, 2672, 2710, 3012, 3018, 3076, 3436, 3438, 3593, 3623, 3648, 3669, 3690, 3722, 3827, 3860, 3877, 3902, 3912, 3989, 4046, 4064, 4080, 4126, 4146, 4179, 4230, 4246, 4478, 4560, 4631, 4687, 4699, 4824, 4996, 5053, 5074, 5126, 5135, 5142, 5146, 5151, 5164, 5226, 5390, 5459, 5635, 5735, 5748, 5754, 5759, 5803, 5998, 6062, 6192, 6249, 6382, 6392, 6412, 6452, 6590, 6610, 6614, 6635, 6768, 6858, 6952, 6972, 6986, 7086, 7189, 7240, 7292, 7319, 7498, 7612, 7719, 7858, 7913, 7930, 8101, 8179])\n",
            "    layer 16: tensor([109, 164, 235, 245, 250, 311, 372, 480, 517, 531, 548, 571, 579, 613, 662, 664, 756, 804, 907, 1013, 1021, 1102, 1117, 1136, 1151, 1195, 1214, 1229, 1239, 1263, 1337, 1415, 1424, 1466, 1517, 1559, 1694, 1735, 1749, 1785, 1912, 1981, 2119, 2165, 2243, 2275, 2344, 2607, 2748, 2749, 2777, 2843, 2968, 3032, 3220, 3224, 3255, 3282, 3348, 3365, 3394, 3454, 3576, 3791, 3832, 3870, 3974, 4017, 4093, 4103, 4224, 4322, 4446, 4458, 4497, 4560, 4617, 4651, 4685, 4716, 4920, 4944, 4958, 5021, 5073, 5104, 5145, 5311, 5377, 5379, 5434, 5445, 5467, 5514, 5595, 5599, 5611, 5731, 5780, 5927, 5947, 6034, 6076, 6317, 6366, 6443, 6623, 6626, 6678, 6750, 6875, 6925, 6956, 7125, 7209, 7232, 7290, 7309, 7312, 7363, 7399, 7428, 7480, 7517, 7544, 7784, 7812, 7813, 8012, 8038, 8051])\n",
            "    layer 17: tensor([37, 123, 129, 201, 220, 285, 302, 474, 622, 668, 697, 710, 726, 942, 1017, 1066, 1127, 1228, 1339, 1366, 1414, 1424, 1450, 1482, 1621, 1685, 1754, 1781, 1820, 1909, 2058, 2083, 2135, 2272, 2278, 2349, 2410, 2570, 2609, 2875, 2938, 2951, 3005, 3074, 3128, 3144, 3341, 3347, 3413, 3421, 3526, 3575, 3593, 3677, 3805, 3898, 3949, 4037, 4143, 4164, 4178, 4242, 4265, 4346, 4411, 4516, 4572, 4629, 4754, 4801, 4872, 5031, 5122, 5173, 5185, 5241, 5332, 5352, 5361, 5375, 5439, 5473, 5490, 5511, 5586, 5626, 5654, 5666, 5671, 5724, 5771, 5784, 5835, 5914, 5979, 6050, 6129, 6144, 6212, 6254, 6400, 6434, 6456, 6485, 6488, 6491, 6527, 6712, 6715, 6859, 6891, 7027, 7120, 7184, 7382, 7422, 7519, 7529, 7591, 7630, 7713, 7892, 7897, 7913, 7915, 8005, 8047])\n",
            "    layer 18: tensor([29, 93, 137, 180, 209, 296, 310, 326, 554, 586, 749, 837, 1017, 1031, 1049, 1132, 1142, 1221, 1243, 1311, 1350, 1358, 1554, 1571, 1613, 1630, 1717, 1760, 1850, 2078, 2193, 2197, 2254, 2286, 2386, 2476, 2535, 2766, 2787, 2792, 2836, 2928, 2961, 2991, 3016, 3215, 3228, 3252, 3277, 3359, 3437, 3502, 3517, 3696, 3794, 3880, 3902, 4005, 4017, 4032, 4058, 4115, 4261, 4284, 4427, 4491, 4513, 4514, 4561, 4738, 4939, 4988, 4998, 5017, 5042, 5066, 5170, 5296, 5445, 5482, 5516, 5767, 5783, 5787, 6061, 6170, 6187, 6227, 6276, 6371, 6431, 6476, 6555, 6572, 6655, 6683, 6714, 6743, 7014, 7089, 7156, 7170, 7173, 7313, 7369, 7435, 7504, 7511, 7544, 7558, 7560, 7678, 7716, 7749, 7819, 7855, 7888, 7948, 7979, 7985])\n",
            "    layer 19: tensor([57, 112, 301, 477, 498, 713, 851, 883, 909, 992, 1015, 1233, 1238, 1275, 1404, 1466, 1513, 1549, 2107, 2138, 2208, 2321, 2439, 2473, 2527, 2638, 2706, 2720, 2802, 2806, 2989, 3004, 3015, 3026, 3044, 3188, 3400, 3412, 3537, 3612, 3641, 3758, 3799, 3813, 3902, 4061, 4065, 4092, 4099, 4184, 4220, 4399, 4412, 4505, 4641, 4649, 4694, 4756, 4884, 4964, 5149, 5304, 5314, 5364, 5448, 5502, 5512, 5583, 5649, 5716, 5763, 5806, 6074, 6280, 6290, 6330, 6409, 6432, 6442, 6615, 6641, 6784, 6949, 7053, 7134, 7210, 7237, 7397, 7417, 7422, 7472, 7484, 7499, 7621, 7670, 7772, 7820, 7944, 8120])\n",
            "    layer 20: tensor([76, 343, 540, 585, 776, 901, 910, 980, 1029, 1057, 1061, 1064, 1112, 1164, 1167, 1282, 1545, 1563, 1670, 1691, 1765, 2001, 2010, 2090, 2142, 2218, 2297, 2380, 2397, 2419, 2460, 2520, 2589, 2614, 2615, 2691, 2736, 2796, 3089, 3355, 3448, 3610, 3616, 3626, 3635, 3654, 3715, 3719, 3885, 4223, 4243, 4333, 4354, 4429, 4694, 4725, 4761, 4762, 4925, 4977, 5063, 5074, 5094, 5146, 5179, 5224, 5239, 5401, 5410, 5606, 5749, 5762, 5806, 5928, 5957, 6008, 6199, 6254, 6328, 6329, 6354, 6630, 6645, 6683, 6735, 6747, 6758, 6782, 6843, 6860, 7117, 7123, 7148, 7304, 7308, 7321, 7553, 7567, 7594, 7649, 7766, 7768, 7845, 7854, 7899, 8121])\n",
            "    layer 21: tensor([113, 122, 157, 225, 240, 284, 500, 574, 627, 748, 854, 884, 1022, 1024, 1030, 1321, 1346, 1439, 1521, 1552, 1627, 1648, 1800, 1916, 1982, 2001, 2029, 2387, 2590, 2650, 2730, 2781, 2834, 2917, 2918, 2939, 2977, 2982, 3045, 3080, 3118, 3135, 3162, 3175, 3372, 3392, 3444, 3507, 3695, 3870, 4043, 4135, 4158, 4190, 4307, 4338, 4480, 4493, 4548, 4636, 4664, 4695, 4831, 4918, 4992, 5093, 5173, 5278, 5323, 5641, 5675, 5773, 5829, 5981, 6064, 6227, 6280, 6479, 6525, 6553, 6555, 6618, 6949, 6962, 6972, 7168, 7184, 7472, 7490, 7509, 7682, 7761, 7778, 7809, 7892, 7957, 8008, 8009, 8014, 8160, 8182])\n",
            "    layer 22: tensor([28, 424, 554, 693, 702, 927, 930, 955, 1014, 1059, 1064, 1185, 1362, 1515, 1546, 1584, 1603, 1636, 1873, 2147, 2165, 2167, 2292, 2434, 2516, 2699, 2705, 2867, 2886, 3008, 3377, 3603, 3634, 3662, 3797, 3833, 3904, 4129, 4242, 4358, 4536, 4576, 4805, 5403, 5456, 5555, 5601, 5676, 5764, 5806, 5943, 6007, 6568, 6617, 6644, 7088, 7238, 7412, 7441, 7541, 7547, 7610, 7749, 7755, 7916, 8009, 8082, 8085])\n",
            "    layer 23: tensor([151, 163, 209, 231, 276, 337, 375, 609, 645, 834, 942, 1061, 1174, 1231, 1397, 1542, 1576, 1605, 1618, 1732, 1858, 1863, 1917, 1918, 2094, 2302, 2314, 2789, 2831, 2843, 2939, 2967, 3009, 3040, 3044, 3081, 3089, 3116, 3218, 3428, 3437, 3629, 3644, 3816, 3992, 4141, 4143, 4240, 4247, 4321, 4419, 4633, 4790, 4934, 5014, 5124, 5210, 5276, 5392, 5501, 5599, 5682, 5693, 5705, 5873, 5874, 5895, 5899, 6008, 6023, 6041, 6141, 6238, 6261, 6291, 6319, 6372, 6400, 6539, 6604, 6642, 6667, 6772, 6904, 7117, 7145, 7348, 7470, 7595, 7773, 7813, 7866, 7957, 8011, 8028, 8101, 8124])\n",
            "    layer 24: tensor([0, 39, 68, 71, 76, 119, 155, 268, 335, 348, 350, 367, 411, 452, 467, 577, 595, 624, 693, 713, 738, 748, 768, 795, 800, 817, 879, 881, 902, 936, 1035, 1191, 1198, 1308, 1414, 1477, 1528, 1607, 1705, 1713, 1919, 2025, 2030, 2063, 2293, 2309, 2341, 2352, 2442, 2491, 2500, 2503, 2513, 2532, 2776, 2821, 3003, 3078, 3098, 3112, 3161, 3190, 3202, 3216, 3253, 3260, 3331, 3343, 3345, 3387, 3400, 3568, 3622, 3776, 3794, 3973, 4011, 4325, 4368, 4446, 4493, 4523, 4532, 4652, 4716, 5014, 5042, 5089, 5158, 5198, 5227, 5237, 5305, 5412, 5568, 5748, 5750, 5803, 5876, 5885, 5908, 6029, 6035, 6134, 6191, 6216, 6226, 6257, 6281, 6327, 6364, 6447, 6497, 6499, 6532, 6562, 6656, 6668, 6839, 6877, 6993, 7327, 7333, 7350, 7398, 7400, 7437, 7443, 7447, 7478, 7483, 7515, 7569, 7617, 7651, 7674, 7883, 7891, 7897, 7931, 7938, 7941, 8008, 8020, 8041, 8096, 8160, 8174, 8183])\n",
            "    layer 25: tensor([20, 39, 222, 271, 343, 378, 434, 496, 511, 550, 611, 685, 734, 749, 824, 985, 1011, 1086, 1132, 1166, 1253, 1260, 1263, 1281, 1335, 1346, 1350, 1484, 1493, 1527, 1538, 1673, 1695, 1705, 1787, 1830, 1844, 1882, 1889, 1962, 2012, 2021, 2051, 2083, 2104, 2161, 2207, 2254, 2382, 2417, 2444, 2493, 2562, 2660, 2686, 2702, 2769, 2799, 2844, 2849, 2875, 2923, 2949, 2974, 3085, 3118, 3164, 3176, 3192, 3213, 3592, 3609, 3750, 3844, 3986, 3992, 4068, 4173, 4190, 4400, 4427, 4514, 4733, 4858, 4886, 4935, 5162, 5234, 5249, 5271, 5340, 5341, 5385, 5403, 5556, 5674, 5690, 5780, 5783, 5794, 5834, 5885, 5964, 5982, 6141, 6239, 6337, 6339, 6356, 6363, 6372, 6375, 6392, 6405, 6408, 6438, 6510, 6511, 6610, 6618, 6628, 6775, 6809, 6835, 6862, 6995, 7076, 7116, 7138, 7165, 7221, 7244, 7308, 7429, 7443, 7468, 7494, 7601, 7680, 7710, 7723, 7873, 7919, 7938, 7942, 8087])\n",
            "    layer 26: tensor([77, 98, 123, 127, 150, 163, 167, 173, 229, 236, 244, 278, 344, 368, 372, 392, 405, 423, 475, 496, 507, 515, 538, 542, 555, 650, 684, 764, 842, 845, 852, 905, 907, 1009, 1138, 1156, 1166, 1232, 1261, 1292, 1293, 1337, 1343, 1376, 1386, 1402, 1467, 1500, 1519, 1524, 1547, 1582, 1594, 1629, 1635, 1657, 1699, 1708, 1752, 1799, 1821, 1895, 1921, 2030, 2074, 2149, 2157, 2242, 2254, 2300, 2347, 2410, 2422, 2432, 2436, 2470, 2471, 2488, 2500, 2512, 2554, 2558, 2572, 2638, 2738, 2827, 3003, 3013, 3032, 3059, 3109, 3110, 3131, 3136, 3148, 3186, 3188, 3210, 3236, 3238, 3243, 3302, 3319, 3325, 3345, 3371, 3390, 3403, 3495, 3526, 3533, 3545, 3558, 3630, 3705, 3724, 3742, 3743, 3763, 3783, 3790, 3813, 3830, 3884, 3897, 3980, 4016, 4025, 4064, 4093, 4138, 4212, 4284, 4291, 4301, 4357, 4384, 4396, 4425, 4437, 4501, 4508, 4512, 4516, 4564, 4587, 4641, 4665, 4695, 4702, 4717, 4719, 4766, 4806, 4874, 4877, 4881, 4926, 5028, 5089, 5154, 5200, 5205, 5251, 5277, 5278, 5325, 5345, 5346, 5347, 5383, 5392, 5420, 5442, 5454, 5492, 5494, 5521, 5526, 5535, 5717, 5719, 5759, 5770, 5783, 5791, 5793, 5798, 5878, 5907, 5918, 5933, 5955, 5993, 6023, 6025, 6055, 6065, 6112, 6171, 6182, 6266, 6288, 6340, 6388, 6452, 6464, 6465, 6466, 6554, 6584, 6594, 6609, 6612, 6669, 6699, 6704, 6716, 6757, 6789, 6866, 6877, 6930, 6984, 6998, 7034, 7044, 7075, 7122, 7155, 7196, 7308, 7329, 7387, 7406, 7446, 7531, 7667, 7669, 7704, 7734, 7737, 7763, 7805, 7818, 7859, 7877, 7906, 7957, 8014, 8076, 8095, 8101, 8166])\n",
            "    layer 27: tensor([105, 122, 168, 298, 307, 373, 389, 402, 455, 504, 525, 526, 589, 628, 638, 642, 645, 657, 662, 828, 830, 850, 856, 866, 925, 1011, 1132, 1155, 1156, 1159, 1205, 1226, 1262, 1264, 1333, 1348, 1352, 1426, 1437, 1451, 1463, 1476, 1488, 1494, 1499, 1535, 1550, 1564, 1625, 1666, 1715, 1720, 1723, 1739, 1777, 1779, 1783, 1794, 1817, 1859, 1865, 1926, 1927, 1961, 1972, 1973, 2021, 2035, 2055, 2070, 2077, 2125, 2151, 2197, 2232, 2251, 2279, 2348, 2368, 2387, 2424, 2483, 2486, 2683, 2689, 2693, 2706, 2749, 2777, 2820, 2828, 2872, 2878, 2899, 2924, 2965, 3073, 3080, 3125, 3185, 3215, 3229, 3233, 3275, 3276, 3317, 3328, 3453, 3500, 3549, 3643, 3649, 3662, 3671, 3684, 3698, 3705, 3711, 3773, 3849, 3884, 3923, 3973, 4030, 4119, 4129, 4159, 4161, 4168, 4171, 4216, 4379, 4387, 4453, 4502, 4503, 4517, 4600, 4651, 4657, 4702, 4719, 4721, 4723, 4726, 4727, 4740, 4767, 4798, 4811, 4819, 4844, 4870, 4876, 4885, 4908, 4949, 4970, 5030, 5054, 5068, 5119, 5124, 5234, 5272, 5273, 5315, 5323, 5334, 5350, 5353, 5384, 5392, 5404, 5416, 5431, 5453, 5474, 5510, 5524, 5538, 5551, 5607, 5609, 5614, 5618, 5619, 5622, 5646, 5652, 5686, 5689, 5707, 5742, 5744, 5769, 5778, 5788, 5800, 5814, 5865, 5871, 5951, 5961, 6025, 6032, 6086, 6137, 6140, 6154, 6179, 6219, 6236, 6243, 6266, 6282, 6310, 6346, 6351, 6368, 6402, 6466, 6468, 6472, 6486, 6492, 6500, 6512, 6526, 6544, 6546, 6604, 6667, 6669, 6674, 6682, 6725, 6741, 6807, 6817, 6838, 6914, 6933, 6940, 6945, 6971, 6982, 7021, 7070, 7080, 7132, 7154, 7194, 7226, 7282, 7285, 7290, 7311, 7357, 7363, 7372, 7393, 7420, 7447, 7453, 7455, 7471, 7476, 7512, 7610, 7612, 7661, 7709, 7710, 7729, 7730, 7823, 7853, 7869, 7873, 7876, 7965, 7997, 8047, 8079, 8143, 8160])\n",
            "]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "output_dir = 'activation_mask'\n",
        "languages = ['en', 'hi']\n",
        "\n",
        "for lang in languages:\n",
        "    file_path = os.path.join(output_dir, f'llama3b_{lang}_mask.pt')\n",
        "\n",
        "    # Load the saved mask\n",
        "    layer_masks = torch.load(file_path)\n",
        "\n",
        "    print(f\"\\n--- Activation mask for {lang.upper()} ---\")\n",
        "    print(\"layer-wise neuron indices = [\")\n",
        "\n",
        "    for i, neuron_tensor in enumerate(layer_masks):\n",
        "        print(f\"    layer {i}: tensor({neuron_tensor.tolist()})\")\n",
        "\n",
        "    print(\"]\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ppl.py**"
      ],
      "metadata": {
        "id": "rF-VYqYMfNQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from types import MethodType\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import os\n",
        "\n",
        "# -------------------- Argument Parser --------------------\n",
        "parser = argparse.ArgumentParser(description=\"Evaluate LLaMA model with language-specific activation masks.\")\n",
        "parser.add_argument(\n",
        "    \"-m\", \"--model\",\n",
        "    type=str,\n",
        "    default=\"meta-llama/Llama-3.2-3B\",\n",
        "    help=\"Model name or path (default: meta-llama/Llama-3.2-3B)\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"-d\", \"--data_dir\",\n",
        "    type=str,\n",
        "    default=\"data\",\n",
        "    help=\"Directory containing tokenized validation data (id.<lang>.valid.llama.pt)\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"-a\", \"--activation_mask_dir\",\n",
        "    type=str,\n",
        "    default=\"activation_mask\",\n",
        "    help=\"Directory containing per-language activation masks (llama3b_<lang>_mask.pt)\"\n",
        ")\n",
        "args, unknown = parser.parse_known_args()\n",
        "if unknown:\n",
        "    print(f\"Ignoring unknown arguments: {unknown}\")\n",
        "\n",
        "# -------------------- Load Model & Tokenizer --------------------\n",
        "print(\"🔹 Loading model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(args.model)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    args.model,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model.eval()\n",
        "print(\"✅ Model loaded.\")\n",
        "\n",
        "num_layers = model.config.num_hidden_layers\n",
        "intermediate_size = model.config.intermediate_size\n",
        "max_length = model.config.max_position_embeddings\n",
        "\n",
        "print(f\"📊 Layers: {num_layers}, Hidden neurons per MLP: {intermediate_size}\")\n",
        "\n",
        "# -------------------- Languages --------------------\n",
        "languages = [\"en\", \"hi\"]\n",
        "\n",
        "# Load activation masks\n",
        "activation_masks = []\n",
        "for lang in languages:\n",
        "    mask_path = os.path.join(args.activation_mask_dir, f\"llama3b_{lang}_mask.pt\")\n",
        "    if os.path.exists(mask_path):\n",
        "        print(f\"🔹 Found activation mask for {lang}: {mask_path}\")\n",
        "        activation_masks.append(torch.load(mask_path))\n",
        "    else:\n",
        "        print(f\"⚠️ No activation mask found for {lang}, using None\")\n",
        "        activation_masks.append(None)\n",
        "\n",
        "# -------------------- Helper: Forward Patch Factory --------------------\n",
        "def factory(mask):\n",
        "    \"\"\"Custom forward method that zeroes out masked neurons.\"\"\"\n",
        "    def llama_forward(self, x):\n",
        "        gate_up = self.gate_proj(x)\n",
        "        up = self.up_proj(x)\n",
        "        activation = F.silu(gate_up) * up\n",
        "\n",
        "        # Zero out masked neurons\n",
        "        if mask is not None and mask.numel() > 0:\n",
        "            activation.index_fill_(2, mask.to(x.device), 0)\n",
        "\n",
        "        return self.down_proj(activation)\n",
        "    return llama_forward\n",
        "\n",
        "# -------------------- Evaluation --------------------\n",
        "final_output = []\n",
        "\n",
        "for activation_mask, mask_lang in zip(activation_masks, languages):\n",
        "    print(f\"\\n🔧 Applying activation mask for: {mask_lang.upper()}\")\n",
        "\n",
        "    # Apply mask to each MLP layer\n",
        "    if activation_mask is not None:\n",
        "        for i, layer_mask in enumerate(activation_mask):\n",
        "            if layer_mask.numel() == 0:\n",
        "                continue\n",
        "            obj = model.model.layers[i].mlp\n",
        "            obj.forward = MethodType(factory(layer_mask), obj)\n",
        "\n",
        "    # -------------------- Evaluate PPL across languages --------------------\n",
        "    ppls = []\n",
        "    for lang in languages:\n",
        "        val_path = os.path.join(args.data_dir, f\"id.{lang}.valid.1M.llama.pt\")\n",
        "        if not os.path.exists(val_path):\n",
        "            print(f\"❌ Missing validation file: {val_path}\")\n",
        "            ppls.append(float(\"nan\"))\n",
        "            continue\n",
        "\n",
        "        ids = torch.load(val_path)\n",
        "        total_len = ids.size(0)\n",
        "        max_len = min(max_length, 1024)\n",
        "        total_len = (total_len // max_len) * max_len\n",
        "        input_ids = ids[:total_len].reshape(-1, max_len)\n",
        "\n",
        "        print(f\"   🔹 Evaluating {lang.upper()} ({input_ids.shape[0]} sequences)...\")\n",
        "\n",
        "        losses = []\n",
        "        for batch in input_ids.to(model.device):\n",
        "            with torch.no_grad():\n",
        "                out = model(batch.unsqueeze(0), labels=batch.unsqueeze(0))\n",
        "                losses.append(out.loss.item())\n",
        "\n",
        "        mean_loss = np.mean(losses)\n",
        "        ppls.append(mean_loss)\n",
        "\n",
        "    final_output.append(ppls)\n",
        "\n",
        "# -------------------- Print Results --------------------\n",
        "print(\"\\n📊 Average Negative Log-Likelihood (proxy for PPL):\")\n",
        "header = \"MASK_LANG | \" + \" | \".join([f\"{l.upper():>5}\" for l in languages])\n",
        "print(header)\n",
        "print(\"-\" * len(header))\n",
        "\n",
        "for mask_lang, ppls in zip(languages, final_output):\n",
        "    row = f\"{mask_lang.upper():>9} | \" + \" | \".join([f\"{ppl:.3f}\" if not np.isnan(ppl) else \"  N/A \" for ppl in ppls])\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "1c1933134d2c43599cd38632b8c2bc7c",
            "f06d901b8bac412f95bb7c1516a9fbf1",
            "aeb22175bb4942de9b814846e5b3fa33",
            "8c2ff5a7060c424e9fee404a80f74764",
            "20068b8943d04737a75474b6b0079465",
            "fe2cb0554fc1432c9d3ec530a02af8bb",
            "2fd626c964c74725b723bb0b44d7d64b",
            "0e1e628bb17248a5baa8a642fd587a63",
            "727b0bf015784c00a6830903758fb2ed",
            "60df747d75da40b89fc41adaed7df8ab",
            "c413610a26e540289118e87e97064cb4"
          ]
        },
        "id": "hnrGOVH8bwah",
        "outputId": "6c1a40a9-8c8a-4b3d-d455-795376575f00"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignoring unknown arguments: ['-f', '/root/.local/share/jupyter/runtime/kernel-bd42ecb1-6f72-46bc-bc20-af423b9f2ca3.json']\n",
            "🔹 Loading model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c1933134d2c43599cd38632b8c2bc7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded.\n",
            "📊 Layers: 28, Hidden neurons per MLP: 8192\n",
            "🔹 Found activation mask for en: activation_mask/llama3b_en_mask.pt\n",
            "🔹 Found activation mask for hi: activation_mask/llama3b_hi_mask.pt\n",
            "\n",
            "🔧 Applying activation mask for: EN\n",
            "   🔹 Evaluating EN (22 sequences)...\n",
            "   🔹 Evaluating HI (22 sequences)...\n",
            "\n",
            "🔧 Applying activation mask for: HI\n",
            "   🔹 Evaluating EN (22 sequences)...\n",
            "   🔹 Evaluating HI (22 sequences)...\n",
            "\n",
            "📊 Average Negative Log-Likelihood (proxy for PPL):\n",
            "MASK_LANG |    EN |    HI\n",
            "-------------------------\n",
            "       EN | 2.162 | 1.579\n",
            "       HI | 2.317 | 1.715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate.py**"
      ],
      "metadata": {
        "id": "NRHINBi0rOv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of prompts\n",
        "prompts = [\n",
        "    \"How can I improve my time management skills?\",\n",
        "    \"What are the most effective ways to deal with stress?\",\n",
        "    \"What are the main differences between Python and JavaScript programming languages?\",\n",
        "    \"How can I increase my productivity while working from home?\",\n",
        "    \"Can you explain the basics of quantum computing?\",\n",
        "    \"What are the differences between plant-based and animal-based protein sources?\",\n",
        "    \"How can I develop my critical thinking skills?\",\n",
        "    \"What are the major challenges faced by the education sector today?\",\n",
        "    \"What are the primary factors that influence consumer behavior?\",\n",
        "    \"What are the most effective strategies for conflict resolution in the workplace?\",\n",
        "    \"What are some potential implications of using a single-use plastic bottle versus a reusable bottle on both the environment and human health?\",\n",
        "    \"What factors would you consider when designing an inclusive and accessible public transportation system?\",\n",
        "    \"How can governments utilize fiscal and monetary policies to combat economic recessions?\",\n",
        "    \"How do language and cultural barriers affect the way people communicate and form relationships in multicultural societies?\",\n",
        "    \"Describe a scenario where artificial intelligence could be used to improve the quality and efficiency of healthcare delivery.\",\n",
        "    \"Explain the process of gene editing using CRISPR-Cas9 technology, and discuss its potential applications and ethical implications.\",\n",
        "    \"How do vaccinations work to protect individuals and communities from infectious diseases, and what is herd immunity?\",\n",
        "    \"How do social media platforms influence the way people consume and share news, and what are the potential implications for the spread of misinformation?\",\n",
        "    \"How do cultural, social, and economic factors influence people's food choices, and how can this knowledge be used to promote healthier diets?\",\n",
        "    \"Explain the process of natural selection and how it contributes to the evolution and adaptation of species.\",\n",
        "    \"How would you introduce yourself as a medieval knight at a royal banquet?\",\n",
        "    \"As a pirate captain, what would you say to your crew to motivate them to search for hidden treasure?\",\n",
        "    \"If you were a Shakespearean character, how would you declare your love for someone in a soliloquy?\",\n",
        "    \"As a superhero, how would you explain your origin story to a curious child?\",\n",
        "    \"Imagine you are a time traveler from the year 3000. What technological advancements would you tell people about?\",\n",
        "    \"As a sports commentator, describe the winning play in the final seconds of a championship game.\",\n",
        "    \"Pretend to be a world-famous chef. How would you describe your signature dish to a panel of judges?\",\n",
        "    \"You are a mountain climber reaching the summit of Mount Everest. Describe your emotions and the view from the top.\",\n",
        "    \"As a space colonist on Mars, describe your daily life and the challenges you face living on another planet.\",\n",
        "    \"Pretend to be a character in a post-apocalyptic world. Describe how you survive and the allies you encounter.\",\n",
        "    \"How can you determine if a restaurant is popular among locals or mainly attracts tourists, and why might this information be useful?\",\n",
        "    \"What are some subtle clues that suggest someone is pretending to understand a topic or conversation when they are actually confused or uninformed?\",\n",
        "    \"Why might someone choose to use a paper map or ask for directions instead of relying on a GPS device or smartphone app?\",\n",
        "    \"How can you determine if a person is genuinely interested in a conversation or simply being polite?\",\n",
        "    \"Why might someone prefer to shop at a small, locally-owned business instead of a large chain store, even if the prices are higher?\",\n",
        "    \"How can you assess the credibility of a source of information, such as a news article or blog post, without relying solely on the reputation of the author or publisher?\",\n",
        "    \"Why do some people enjoy the sensation of being scared, such as by watching horror movies or going on roller coasters, while others avoid these experiences?\",\n",
        "    \"How can observing the behavior of other people in a social situation provide clues about cultural norms and expectations?\",\n",
        "    \"Do we have a moral obligation to explore space, or should we focus on solving Earth's problems first?\",\n",
        "    \"In a world where automation is becoming increasingly prevalent, is it more important to prioritize job creation or technological progress?\",\n",
        "    \"How many times does the average human blink in a lifetime? Try to explain your answer step-by-step.\",\n",
        "    \"How many atoms are in a grain of salt? Try to explain your answer step-by-step.\",\n",
        "    \"How many lightning strikes occur on Earth each day? Try to explain your answer step-by-step.\",\n",
        "    \"How many balloons would it take to lift a house like in the movie 'Up'? Try to explain your answer step-by-step.\",\n",
        "    \"How many text messages are sent globally in a minute? Try to explain your answer step-by-step.\",\n",
        "    \"How many words are spoken daily on Earth? Try to explain your answer step-by-step.\",\n",
        "    \"How many snowflakes fall during a typical winter? Try to explain your answer step-by-step.\",\n",
        "    \"How many pages are in all the books ever written? Try to explain your answer step-by-step.\",\n",
        "    \"How many times has the Earth orbited the Sun since the beginning of life? Try to explain your answer step-by-step.\",\n",
        "    \"How many songs have been recorded throughout history? Try to explain your answer step-by-step.\",\n",
        "    \"What if the Internet had been invented during the Renaissance period?\",\n",
        "    \"What if the Aztecs had successfully repelled the Spanish conquistadors?\",\n",
        "    \"What if the Black Death had not occurred in the 14th century?\",\n",
        "    \"What if Isaac Newton had focused on biology instead of physics?\",\n",
        "    \"What if the Beatles had never formed as a band?\",\n",
        "    \"What if Alan Turing had not cracked the Enigma code during World War II?\",\n",
        "    \"What if the Suez Canal had never been constructed?\",\n",
        "    \"What if the Maya civilization had never mysteriously collapsed?\",\n",
        "    \"What if Christopher Columbus had not discovered the Americas?\",\n",
        "    \"What if Vincent van Gogh had been a successful artist during his lifetime?\",\n",
        "    \"Can you help me write a formal email to a potential business partner proposing a joint venture?\",\n",
        "    \"Can you help me write a resignation letter to my current employer, while leaving on good terms and expressing gratitude for the opportunities provided?\",\n",
        "    \"Use an appropriate format to structure a formal letter of recommendation for a student applying to a prestigious graduate program in computer science.\",\n",
        "    \"Write a compelling product launch announcement email to inform our customers of our new software solution.\",\n",
        "    \"Draft an apology email to a customer who experienced a delay in their order, and provide reassurance that the issue has been resolved.\",\n",
        "    \"Write a script for a YouTube video exploring the history and cultural significance of jazz.\",\n",
        "    \"Compose an engaging travel blog post about a recent trip to Hawaii, highlighting cultural experiences and must-see attractions.\",\n",
        "    \"Write a captivating movie review for a recently released science fiction film, discussing its plot, characters, and special effects.\",\n",
        "    \"Structure a podcast script for an episode discussing the influence of streaming platforms on the music industry.\",\n",
        "    \"Write a symphony concert review, discussing the orchestra's performance and overall audience experience.\"\n",
        "]\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(\"dataset/mvicuna\", exist_ok=True)\n",
        "\n",
        "# Write prompts to en.txt\n",
        "with open(\"dataset/mvicuna/en.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for prompt in prompts:\n",
        "        f.write(prompt + \"\\n\")\n",
        "\n",
        "print(\"✅ Saved prompts to dataset/mvicuna/en.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI6Om3FnrnYn",
        "outputId": "4ec78410-c34f-4ef9-d926-9d810b6c0487"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved prompts to dataset/mvicuna/en.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hi_prompts = [\n",
        "    # Self-improvement\n",
        "    \"मैं अपने समय प्रबंधन कौशल को कैसे सुधार सकता हूँ?\",\n",
        "    \"तनाव से निपटने के सबसे प्रभावी तरीके क्या हैं?\",\n",
        "    \"मैं अपनी आलोचनात्मक सोच कौशल कैसे विकसित कर सकता हूँ?\",\n",
        "    \"घर से काम करते समय अपनी उत्पादकता कैसे बढ़ा सकता हूँ?\",\n",
        "    \"सकारात्मक आदतें विकसित करने के लिए क्या कदम उठाए जा सकते हैं?\",\n",
        "\n",
        "    # Science & Technology\n",
        "    \"क्वांटम कंप्यूटिंग की मूल बातें समझाइए।\",\n",
        "    \"CRISPR-Cas9 तकनीक के माध्यम से जीन संपादन की प्रक्रिया बताइए।\",\n",
        "    \"वैक्सीन कैसे काम करती हैं और हर्ड इम्युनिटी क्या है?\",\n",
        "    \"प्लास्टिक की एकल-उपयोग वाली बोतल और पुन: प्रयोज्य बोतल का पर्यावरण और स्वास्थ्य पर क्या प्रभाव पड़ता है?\",\n",
        "    \"Python और JavaScript प्रोग्रामिंग भाषाओं के मुख्य अंतर क्या हैं?\",\n",
        "\n",
        "    # Daily life & practical scenarios\n",
        "    \"घर से काम करते समय समय और ऊर्जा का प्रबंधन कैसे करें?\",\n",
        "    \"सामाजिक स्थितियों में दूसरों के व्यवहार को देखकर सांस्कृतिक नियम कैसे समझे जा सकते हैं?\",\n",
        "    \"एक रेस्टोरेंट की लोकप्रियता को कैसे परखा जा सकता है?\",\n",
        "    \"किसी स्रोत की विश्वसनीयता का मूल्यांकन कैसे किया जाए?\",\n",
        "    \"व्यक्तिगत और व्यावसायिक जीवन में ध्यान और फोकस कैसे बनाए रखें?\",\n",
        "\n",
        "    # Imaginative & creative scenarios\n",
        "    \"एक समुद्री डाकू कप्तान के रूप में अपने क्रू को खजाना खोजने के लिए कैसे प्रोत्साहित करेंगे?\",\n",
        "    \"यदि आप एक सुपरहीरो हों, तो अपने उत्पत्ति की कहानी कैसे बताएंगे?\",\n",
        "    \"कल्पना कीजिए कि आप वर्ष 3000 से समय यात्री हैं। लोगों को किन तकनीकी विकासों के बारे में बताएंगे?\",\n",
        "    \"एक अंतरिक्ष उपनिवेशकर्ता के रूप में मंगल पर अपने दैनिक जीवन और चुनौतियों का वर्णन कीजिए।\",\n",
        "    \"पोस्ट-एपोकैलिप्टिक दुनिया में एक पात्र के रूप में अपने उत्तरजीविता कौशल का वर्णन करें।\",\n",
        "\n",
        "    # History & what-if scenarios\n",
        "    \"यदि ब्लैक डेथ 14वीं सदी में नहीं हुआ होता तो क्या होता?\",\n",
        "    \"अगर बीटल्स कभी एक बैंड के रूप में नहीं बने होते तो संगीत उद्योग पर क्या प्रभाव पड़ता?\",\n",
        "    \"यदि क्रिस्टोफर कोलंबस ने अमेरिका की खोज नहीं की होती तो इतिहास कैसे बदलता?\",\n",
        "    \"यदि माया सभ्यता अचानक ढह न जाती तो क्या होता?\",\n",
        "    \"यदि न्यूटन ने भौतिकी के बजाय जीवविज्ञान पर ध्यान केंद्रित किया होता तो क्या होता?\",\n",
        "\n",
        "    # Science & estimation questions\n",
        "    \"एक मानक वर्ष में पृथ्वी पर कितने बिजली गिरते हैं?\",\n",
        "    \"एक साल में मानव शरीर में औसतन कितनी बार पलक झपकते हैं?\",\n",
        "    \"एक ग्रेन नमक में कितने परमाणु होते हैं? इसका अनुमान बताइए।\",\n",
        "    \"एक मिनट में दुनिया भर में कितने टेक्स्ट संदेश भेजे जाते हैं?\",\n",
        "    \"पृथ्वी पर प्रतिदिन कितने शब्द बोले जाते हैं? इसका अनुमान लगाइए।\",\n",
        "\n",
        "    # Practical writing tasks\n",
        "    \"एक व्यवसायिक सहयोग के लिए औपचारिक ईमेल कैसे लिखा जाए?\",\n",
        "    \"ग्राहक को देर हुए आदेश के लिए माफी का पत्र कैसे लिखा जाए?\",\n",
        "    \"कंप्यूटर विज्ञान में स्नातक छात्र के लिए सिफारिश पत्र कैसे लिखा जाए?\",\n",
        "    \"नई सॉफ़्टवेयर सुविधा की घोषणा के लिए आकर्षक ईमेल कैसे लिखा जाए?\",\n",
        "    \"यूट्यूब वीडियो के लिए स्क्रिप्ट कैसे तैयार की जाए जो इतिहास और सांस्कृतिक महत्व पर हो?\",\n",
        "\n",
        "    # Food & lifestyle\n",
        "    \"सांस्कृतिक, सामाजिक और आर्थिक कारक लोगों की भोजन पसंद को कैसे प्रभावित करते हैं?\",\n",
        "    \"शाकाहारी और मांसाहारी प्रोटीन स्रोतों के बीच मुख्य अंतर क्या हैं?\",\n",
        "    \"स्वस्थ आहार को बढ़ावा देने के लिए लोगों के भोजन चुनाव का विश्लेषण कैसे किया जाए?\",\n",
        "    \"आप किसी रेस्तरां में अपने अनुभव और व्यंजन का वर्णन कैसे करेंगे?\",\n",
        "    \"स्थानीय बाजार में खरीदारी करने के क्या फायदे हैं, और लोग इसे क्यों चुनते हैं?\",\n",
        "\n",
        "    # Miscellaneous fun & curiosity\n",
        "    \"यदि आप मध्यकालीन शूरवीर होते, तो शाही भोज में खुद को कैसे पेश करते?\",\n",
        "    \"यदि आप शेक्सपियरियन पात्र होते, तो किसी से प्रेम कैसे घोषित करते?\",\n",
        "    \"यदि आप प्रसिद्ध शेफ होते, तो अपनी खास डिश का वर्णन कैसे करते?\",\n",
        "    \"यदि आप समय यात्री होते, तो प्राचीन सभ्यताओं को क्या ज्ञान देते?\",\n",
        "    \"यदि आप स्पेस कमांडर होते, तो मंगल पर जीवन का दैनिक विवरण कैसे देंगे?\"\n",
        "]\n",
        "\n",
        "import os\n",
        "os.makedirs(\"dataset/mvicuna\", exist_ok=True)\n",
        "with open(\"dataset/mvicuna/hi.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for prompt in hi_prompts:\n",
        "        f.write(prompt + \"\\n\")\n",
        "\n",
        "print(\"✅ Hindi prompts saved to dataset/mvicuna/hi.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JbLg9MRr7Fg",
        "outputId": "afc808f6-207e-4313-cfb4-1504af18b0cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Hindi prompts saved to dataset/mvicuna/hi.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from types import MethodType\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------------------- Configuration --------------------\n",
        "MODEL_NAME = \"meta-llama/Llama-3.2-3B\"\n",
        "DATA_DIR = \"dataset/mvicuna\"  # folder with your question datasets per language\n",
        "ACTIVATION_MASK_DIR = \"activation_mask\"  # folder with per-language masks\n",
        "OUTPUT_DIR = f\"results/{MODEL_NAME.split('/')[-1]}/mvicuna\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "LANGUAGES = [\"en\", \"hi\"]\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "answer_lang = {\n",
        "    \"en\": \" Answer in English.\",\n",
        "    \"hi\": \" Answer in Hindi.\",  # you can customize or use the same as English\n",
        "}\n",
        "\n",
        "# -------------------- Load model and tokenizer --------------------\n",
        "print(\"🔹 Loading model and tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "model.eval()\n",
        "print(\"✅ Model loaded.\")\n",
        "num_layers = model.config.num_hidden_layers\n",
        "intermediate_size = model.config.intermediate_size\n",
        "print(f\"📊 Layers: {num_layers}, Hidden neurons per MLP: {intermediate_size}\")\n",
        "\n",
        "# -------------------- Load activation masks --------------------\n",
        "activation_masks = {}\n",
        "for lang in LANGUAGES:\n",
        "    mask_path = os.path.join(ACTIVATION_MASK_DIR, f\"llama3b_{lang}_mask.pt\")\n",
        "    if os.path.exists(mask_path):\n",
        "        activation_masks[lang] = torch.load(mask_path)\n",
        "        print(f\"🔹 Found activation mask for {lang}: {mask_path}\")\n",
        "    else:\n",
        "        activation_masks[lang] = None\n",
        "        print(f\"⚠️ No activation mask found for {lang}\")\n",
        "\n",
        "# -------------------- Helper: Patch forward function --------------------\n",
        "def mlp_forward_factory(mask):\n",
        "    \"\"\"Return a patched forward method that zeros out neurons in the mask.\"\"\"\n",
        "    def forward(self, x):\n",
        "        gate_up = self.gate_proj(x)\n",
        "        up = self.up_proj(x)\n",
        "        activation = F.silu(gate_up) * up\n",
        "        if mask is not None and mask.numel() > 0:\n",
        "            activation.index_fill_(2, mask.to(x.device), 0)\n",
        "        return self.down_proj(activation)\n",
        "    return forward\n",
        "\n",
        "# -------------------- Run inference per mask --------------------\n",
        "for mask_lang, mask in activation_masks.items():\n",
        "    # Patch model MLPs for this mask\n",
        "    if mask is not None:\n",
        "        for i, layer_mask in enumerate(mask):\n",
        "            if layer_mask.numel() == 0:\n",
        "                continue\n",
        "            mlp_layer = model.model.layers[i].mlp\n",
        "            mlp_layer.forward = MethodType(mlp_forward_factory(layer_mask), mlp_layer)\n",
        "\n",
        "    # Run inference on EN and HI datasets\n",
        "    for lang in LANGUAGES:\n",
        "        input_file = os.path.join(DATA_DIR, f\"{lang}.txt\")\n",
        "        if not os.path.exists(input_file):\n",
        "            print(f\"❌ Missing dataset for {lang}: {input_file}\")\n",
        "            continue\n",
        "\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            texts = [line.strip() + answer_lang[lang] for line in f if line.strip()]\n",
        "            texts = [f\"Q: {t}\\nA:\" for t in texts]\n",
        "\n",
        "        results = []\n",
        "        for t in tqdm(texts, desc=f\"{lang} <- mask {mask_lang}\"):\n",
        "            input_ids = tokenizer(t, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "                output_ids = model.generate(input_ids, max_new_tokens=256)\n",
        "            output_text = tokenizer.decode(output_ids[0][input_ids.size(1):], skip_special_tokens=True)\n",
        "            results.append({\"input\": t, \"output\": output_text})\n",
        "\n",
        "        # Save results\n",
        "        if mask is not None:\n",
        "            out_file = os.path.join(OUTPUT_DIR, f\"{lang}.perturb.{mask_lang}.jsonl\")\n",
        "        else:\n",
        "            out_file = os.path.join(OUTPUT_DIR, f\"{lang}.jsonl\")\n",
        "\n",
        "        with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            for r in results:\n",
        "                f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "        print(f\"✅ Saved results: {out_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a10b46010ca142a780a8d9de2e4ac4e2",
            "124b9561334540c1b768dea6d7e9004e",
            "f47a533f9ee74567bb24b5d91a643a1f",
            "8a5163039e5c4c0cbfdd1d997280f6b9",
            "4b44dae176f744bbae7c62dc5c2232b1",
            "e117d1f53fe04d34b6152af2e4e2b53b",
            "d13e49e5951c4343b2fc50ceb0672e3d",
            "11f920357cbb4727bc473de9e9c2b28d",
            "fa339f2a5ac049e7891d19117879eff3",
            "afeb06c3b9de46a69ef0984adbd4f576",
            "5abf158dfe5742d7abaaf48ced507136"
          ]
        },
        "id": "NWd0sKKrpcov",
        "outputId": "503f5dff-e2aa-4077-88b6-01f5487dbf40"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Loading model and tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a10b46010ca142a780a8d9de2e4ac4e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded.\n",
            "📊 Layers: 28, Hidden neurons per MLP: 8192\n",
            "🔹 Found activation mask for en: activation_mask/llama3b_en_mask.pt\n",
            "🔹 Found activation mask for hi: activation_mask/llama3b_hi_mask.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\ren <- mask en:   0%|          | 0/70 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "en <- mask en:   1%|▏         | 1/70 [00:12<13:54, 12.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:   3%|▎         | 2/70 [00:22<12:36, 11.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:   4%|▍         | 3/70 [00:38<15:07, 13.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:   6%|▌         | 4/70 [00:51<14:16, 12.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:   7%|▋         | 5/70 [01:00<12:36, 11.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:   9%|▊         | 6/70 [01:10<11:50, 11.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  10%|█         | 7/70 [01:20<11:21, 10.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  11%|█▏        | 8/70 [01:31<11:03, 10.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  13%|█▎        | 9/70 [01:41<10:47, 10.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  14%|█▍        | 10/70 [01:51<10:33, 10.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  16%|█▌        | 11/70 [02:02<10:20, 10.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  17%|█▋        | 12/70 [02:12<10:06, 10.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  19%|█▊        | 13/70 [02:22<09:44, 10.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  20%|██        | 14/70 [02:32<09:35, 10.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  21%|██▏       | 15/70 [02:43<09:26, 10.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  23%|██▎       | 16/70 [02:53<09:17, 10.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  24%|██▍       | 17/70 [02:57<07:30,  8.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  26%|██▌       | 18/70 [03:08<07:51,  9.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  27%|██▋       | 19/70 [03:18<08:04,  9.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  29%|██▊       | 20/70 [03:22<06:26,  7.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  30%|███       | 21/70 [03:32<06:58,  8.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  31%|███▏      | 22/70 [03:43<07:16,  9.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  33%|███▎      | 23/70 [03:53<07:26,  9.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  34%|███▍      | 24/70 [04:03<07:29,  9.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  36%|███▌      | 25/70 [04:14<07:26,  9.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  37%|███▋      | 26/70 [04:24<07:15,  9.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  39%|███▊      | 27/70 [04:34<07:11, 10.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  40%|████      | 28/70 [04:44<07:06, 10.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  41%|████▏     | 29/70 [04:55<06:58, 10.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  43%|████▎     | 30/70 [05:05<06:50, 10.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  44%|████▍     | 31/70 [05:15<06:42, 10.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  46%|████▌     | 32/70 [05:25<06:28, 10.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  47%|████▋     | 33/70 [05:36<06:19, 10.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  49%|████▊     | 34/70 [05:43<05:34,  9.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  50%|█████     | 35/70 [05:53<05:36,  9.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  51%|█████▏    | 36/70 [06:04<05:36,  9.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  53%|█████▎    | 37/70 [06:07<04:23,  7.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  54%|█████▍    | 38/70 [06:18<04:38,  8.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  56%|█████▌    | 39/70 [06:23<04:02,  7.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  57%|█████▋    | 40/70 [06:34<04:18,  8.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  59%|█████▊    | 41/70 [06:36<03:09,  6.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  60%|██████    | 42/70 [06:38<02:32,  5.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  61%|██████▏   | 43/70 [06:49<03:06,  6.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  63%|██████▎   | 44/70 [06:49<02:08,  4.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  64%|██████▍   | 45/70 [07:00<02:45,  6.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  66%|██████▌   | 46/70 [07:10<03:06,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  67%|██████▋   | 47/70 [07:21<03:17,  8.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  69%|██████▊   | 48/70 [07:31<03:21,  9.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  70%|███████   | 49/70 [07:42<03:20,  9.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  71%|███████▏  | 50/70 [07:52<03:13,  9.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  73%|███████▎  | 51/70 [08:02<03:07,  9.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  74%|███████▍  | 52/70 [08:12<03:00, 10.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  76%|███████▌  | 53/70 [08:23<02:52, 10.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  77%|███████▋  | 54/70 [08:28<02:16,  8.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  79%|███████▊  | 55/70 [08:38<02:14,  8.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  80%|████████  | 56/70 [08:48<02:12,  9.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  81%|████████▏ | 57/70 [08:59<02:06,  9.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  83%|████████▎ | 58/70 [09:09<01:59,  9.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  84%|████████▍ | 59/70 [09:19<01:50, 10.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  86%|████████▌ | 60/70 [09:30<01:40, 10.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  87%|████████▋ | 61/70 [09:40<01:31, 10.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  89%|████████▊ | 62/70 [09:46<01:13,  9.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  90%|█████████ | 63/70 [09:57<01:06,  9.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  91%|█████████▏| 64/70 [10:07<00:58,  9.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  93%|█████████▎| 65/70 [10:16<00:46,  9.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  94%|█████████▍| 66/70 [10:26<00:38,  9.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  96%|█████████▌| 67/70 [10:36<00:29,  9.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  97%|█████████▋| 68/70 [10:45<00:19,  9.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en:  99%|█████████▊| 69/70 [10:56<00:09,  9.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "en <- mask en: 100%|██████████| 70/70 [11:06<00:00,  9.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved results: results/Llama-3.2-3B/mvicuna/en.perturb.en.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rhi <- mask en:   0%|          | 0/45 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:   2%|▏         | 1/45 [00:10<07:35, 10.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:   4%|▍         | 2/45 [00:20<07:26, 10.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:   7%|▋         | 3/45 [00:31<07:17, 10.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:   9%|▉         | 4/45 [00:41<07:07, 10.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  11%|█         | 5/45 [00:52<06:56, 10.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  13%|█▎        | 6/45 [01:02<06:42, 10.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  16%|█▌        | 7/45 [01:12<06:29, 10.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  18%|█▊        | 8/45 [01:22<06:20, 10.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  20%|██        | 9/45 [01:24<04:40,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  22%|██▏       | 10/45 [01:35<05:01,  8.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  24%|██▍       | 11/45 [01:45<05:12,  9.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  27%|██▋       | 12/45 [01:56<05:16,  9.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  29%|██▉       | 13/45 [01:59<04:05,  7.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  31%|███       | 14/45 [02:10<04:23,  8.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  33%|███▎      | 15/45 [02:13<03:26,  6.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  36%|███▌      | 16/45 [02:23<03:50,  7.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  38%|███▊      | 17/45 [02:34<04:03,  8.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  40%|████      | 18/45 [02:44<04:08,  9.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  42%|████▏     | 19/45 [02:54<04:08,  9.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  44%|████▍     | 20/45 [03:05<04:05,  9.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  47%|████▋     | 21/45 [03:14<03:55,  9.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  49%|████▉     | 22/45 [03:15<02:44,  7.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  51%|█████     | 23/45 [03:26<02:57,  8.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  53%|█████▎    | 24/45 [03:36<03:03,  8.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "hi <- mask en:  53%|█████▎    | 24/45 [03:41<03:14,  9.25s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1558827796.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0moutput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 459\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2373\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2375\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Replace 'folder_name' with your folder\n",
        "folders_to_download = ['data', 'dataset']\n",
        "\n",
        "for folder in folders_to_download:\n",
        "    zip_name = f\"{folder}.zip\"\n",
        "    shutil.make_archive(folder, 'zip', folder)\n",
        "    files.download(zip_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PnzM9Yu0sUBf",
        "outputId": "20ef7fae-e967-4060-cd6e-e5f6d9ea99fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e3a84672-d394-4e46-862f-77a262a6383c\", \"data.zip\", 10203180)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fe5c4c51-6d2c-44ef-a6ef-388cf6ee2a27\", \"dataset.zip\", 5337)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "folders_to_download = ['data', 'dataset']\n",
        "\n",
        "for folder in folders_to_download:\n",
        "    zip_name = f\"/content/drive/MyDrive/{folder}.zip\"\n",
        "    shutil.make_archive(f\"/content/{folder}\", 'zip', folder)\n",
        "    shutil.move(f\"/content/{folder}.zip\", zip_name)\n",
        "    print(f\"✅ {folder} saved to Google Drive: {zip_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQEDxplvw5QQ",
        "outputId": "5c79f84d-fdce-4b96-e0d8-2fcd36e58e9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ data saved to Google Drive: /content/drive/MyDrive/data.zip\n",
            "✅ dataset saved to Google Drive: /content/drive/MyDrive/dataset.zip\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24a54c4b9a8348ad88dcf8a7ffeb2236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_2a00c554f771434cba698eab7a1cbd5c"
          }
        },
        "d972b0a560784c4c9be9c015efe98bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99c6a1b6ff214d0abd7689521f657a74",
            "placeholder": "​",
            "style": "IPY_MODEL_8c363696432d42b99635ef1d4c81dfb0",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "273fd53527b54bd98625fdc591261fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_710b09cc61254530898488156362fcd0",
            "placeholder": "​",
            "style": "IPY_MODEL_8019ab3b505a494ebb4154a2c56d63dd",
            "value": ""
          }
        },
        "dfc7abb8d2de495394ab54a5111d7455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_5432cc4121994387abd277f7333f7e78",
            "style": "IPY_MODEL_82e9cf491ed54be6ae470c76d87d1ebc",
            "value": true
          }
        },
        "63a2915e1a0d4758a063442c0d0e304e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_dbf255681a8b440e8468d617b7db2790",
            "style": "IPY_MODEL_32a9c815badc441998291533f7e114be",
            "tooltip": ""
          }
        },
        "d06203cb91784780a7cea1413794b87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da0beb2d0d7f42138f3783a64e390355",
            "placeholder": "​",
            "style": "IPY_MODEL_83ed0ddd19984f238b33b64a3e6376a1",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "2a00c554f771434cba698eab7a1cbd5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "99c6a1b6ff214d0abd7689521f657a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c363696432d42b99635ef1d4c81dfb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "710b09cc61254530898488156362fcd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8019ab3b505a494ebb4154a2c56d63dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5432cc4121994387abd277f7333f7e78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e9cf491ed54be6ae470c76d87d1ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbf255681a8b440e8468d617b7db2790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a9c815badc441998291533f7e114be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "da0beb2d0d7f42138f3783a64e390355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83ed0ddd19984f238b33b64a3e6376a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "526f806ffd19490185fec83def0be2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c90372920855432f91efcb8a09e21062",
            "placeholder": "​",
            "style": "IPY_MODEL_07f6834e91a8458997795636ddcf183b",
            "value": "Connecting..."
          }
        },
        "c90372920855432f91efcb8a09e21062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f6834e91a8458997795636ddcf183b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "041a8aaa0405463a80ca9e79e3a8e5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c7eebba9138451e9f9259dd844eb69e",
              "IPY_MODEL_d863f4b18a5646d19cefad9739ae5ad3",
              "IPY_MODEL_d9d7b91ec95d46c8b0522943cfefce64"
            ],
            "layout": "IPY_MODEL_99a130083a83458186978d802188265f"
          }
        },
        "7c7eebba9138451e9f9259dd844eb69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b32806f1214435183802cacbe3c1bf8",
            "placeholder": "​",
            "style": "IPY_MODEL_693de824dffd492abb9ae78ba6d9d837",
            "value": "Resolving data files: 100%"
          }
        },
        "d863f4b18a5646d19cefad9739ae5ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54249ff9b28e41fe903b738af96c98bf",
            "max": 41,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e49baae21b8842fd955c09f886883f0f",
            "value": 41
          }
        },
        "d9d7b91ec95d46c8b0522943cfefce64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_383a6c7db98248ba9a3a1264b2e8edc9",
            "placeholder": "​",
            "style": "IPY_MODEL_e2d1a3873e5d4662bbd92287bd49d4c2",
            "value": " 41/41 [00:00&lt;00:00, 45.93it/s]"
          }
        },
        "99a130083a83458186978d802188265f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b32806f1214435183802cacbe3c1bf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693de824dffd492abb9ae78ba6d9d837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54249ff9b28e41fe903b738af96c98bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e49baae21b8842fd955c09f886883f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "383a6c7db98248ba9a3a1264b2e8edc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d1a3873e5d4662bbd92287bd49d4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a589bb4fbc34a35966fe0ef329f9750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acc219b182b3400aa60c3fa7e81e2d4a",
              "IPY_MODEL_d61dfd854c3b4b8991b96979ab9e991b",
              "IPY_MODEL_148aa7658ca9420bbecaf3352f95ac19"
            ],
            "layout": "IPY_MODEL_05598cc09e0c40a8be93265aba042a68"
          }
        },
        "acc219b182b3400aa60c3fa7e81e2d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc0b2c5a23a149bf8d7b3ca3d2bb8cb9",
            "placeholder": "​",
            "style": "IPY_MODEL_a5128e72222b4f0ea09d694ce812cea5",
            "value": "Tokenizing en: "
          }
        },
        "d61dfd854c3b4b8991b96979ab9e991b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0509a20679de4e2c810c3ab11da3dcd0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14dc03457b724bca8a19a0ef8dc8ac8b",
            "value": 1
          }
        },
        "148aa7658ca9420bbecaf3352f95ac19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6b8d0123549442dbd65c7afb0ba6bb0",
            "placeholder": "​",
            "style": "IPY_MODEL_e84d9dc3c19f49078f00ccccbae9e8ef",
            "value": " 33051/? [00:04&lt;00:00, 7982.39line/s]"
          }
        },
        "05598cc09e0c40a8be93265aba042a68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc0b2c5a23a149bf8d7b3ca3d2bb8cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5128e72222b4f0ea09d694ce812cea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0509a20679de4e2c810c3ab11da3dcd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "14dc03457b724bca8a19a0ef8dc8ac8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6b8d0123549442dbd65c7afb0ba6bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84d9dc3c19f49078f00ccccbae9e8ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ffe5ec032b84f339c2e6e3bbfbdd00a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06dded1484914aa2b85183f09e05564a",
              "IPY_MODEL_60dc3594bae64d5d87f515d40cd6ec68",
              "IPY_MODEL_3431a7399cc641578e92a459d31dca52"
            ],
            "layout": "IPY_MODEL_4ef32b90ddf64fdda32be53307bffb59"
          }
        },
        "06dded1484914aa2b85183f09e05564a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98db2e0480a64e16a64033c556870974",
            "placeholder": "​",
            "style": "IPY_MODEL_964a0696923d4a98915f520c0167fd07",
            "value": "Tokenizing hi: "
          }
        },
        "60dc3594bae64d5d87f515d40cd6ec68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6be5aa92ebe40d69170ca0747bb57c3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a5a80caffba48db95fa4b86c841ed13",
            "value": 1
          }
        },
        "3431a7399cc641578e92a459d31dca52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ccc65d1f06c4b269644ea56f420271d",
            "placeholder": "​",
            "style": "IPY_MODEL_e519a560fc1c413ebff0c30fe0cb298d",
            "value": " 17909/? [00:03&lt;00:00, 5465.40line/s]"
          }
        },
        "4ef32b90ddf64fdda32be53307bffb59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98db2e0480a64e16a64033c556870974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "964a0696923d4a98915f520c0167fd07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6be5aa92ebe40d69170ca0747bb57c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1a5a80caffba48db95fa4b86c841ed13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ccc65d1f06c4b269644ea56f420271d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e519a560fc1c413ebff0c30fe0cb298d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60c705976808428591889b82a68c215f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18d62d688b604be78e9365a54e3ec2ed",
              "IPY_MODEL_0faf9044659e4427a94b2d7a1aebdfd2",
              "IPY_MODEL_087c289b7f4440e39c4ca9d5c110a98a"
            ],
            "layout": "IPY_MODEL_2588bd2416414005953bef245afbfa66"
          }
        },
        "18d62d688b604be78e9365a54e3ec2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a6a48918afc436f852da80c416b3cd0",
            "placeholder": "​",
            "style": "IPY_MODEL_23a887eeaea94318b3eaf078857c7332",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0faf9044659e4427a94b2d7a1aebdfd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_621b34ea0cf04cab9fd3db2477fff8d9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75c0bd51b74041e09d78f5d288ae4082",
            "value": 2
          }
        },
        "087c289b7f4440e39c4ca9d5c110a98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7a97815f6934a878b90825652dacaa0",
            "placeholder": "​",
            "style": "IPY_MODEL_c977a95a59d54b618d8a2e71d3cb634c",
            "value": " 2/2 [00:15&lt;00:00,  8.27s/it]"
          }
        },
        "2588bd2416414005953bef245afbfa66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a6a48918afc436f852da80c416b3cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a887eeaea94318b3eaf078857c7332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "621b34ea0cf04cab9fd3db2477fff8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c0bd51b74041e09d78f5d288ae4082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7a97815f6934a878b90825652dacaa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c977a95a59d54b618d8a2e71d3cb634c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c8a67f65f3d43afa449e67a54c09e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0a5ec90e84a4a79a7988bd7d332c896",
              "IPY_MODEL_789af59404404a29816432fad5b654e9",
              "IPY_MODEL_f3d6d18b1f9d4eaa879e860599d8293f"
            ],
            "layout": "IPY_MODEL_0a76234ade4046c7b63cb3be45bef91c"
          }
        },
        "b0a5ec90e84a4a79a7988bd7d332c896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_508a66609d874233b77585a1b7672cb9",
            "placeholder": "​",
            "style": "IPY_MODEL_15486604610449a79040d8c5fcd56158",
            "value": "🔄 Forward passes for en: 100%"
          }
        },
        "789af59404404a29816432fad5b654e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5448848d76a546bf869546eda767e8da",
            "max": 217,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65c8496c9669406aaae7e836211848ce",
            "value": 217
          }
        },
        "f3d6d18b1f9d4eaa879e860599d8293f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2397e1aea68544e8877da237d6f58b25",
            "placeholder": "​",
            "style": "IPY_MODEL_dd90de49463146c3a29befd6f5d02613",
            "value": " 217/217 [05:03&lt;00:00,  1.30s/it]"
          }
        },
        "0a76234ade4046c7b63cb3be45bef91c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "508a66609d874233b77585a1b7672cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15486604610449a79040d8c5fcd56158": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5448848d76a546bf869546eda767e8da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65c8496c9669406aaae7e836211848ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2397e1aea68544e8877da237d6f58b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd90de49463146c3a29befd6f5d02613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b699254e3a87438eaffed7ac304b5f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d9bf87aca664665998e6a912192a71d",
              "IPY_MODEL_3b1ce9b60bc14529bd73d10ab10d7e99",
              "IPY_MODEL_470b782e4c704fe2a64819f23c68ec62"
            ],
            "layout": "IPY_MODEL_77e0baf0ffb34c2bb5902ea63a1c91b9"
          }
        },
        "6d9bf87aca664665998e6a912192a71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e99c549e2f85402fb8335a2793ba55c7",
            "placeholder": "​",
            "style": "IPY_MODEL_c0fa37d409a94466a7f180593a249134",
            "value": "🔄 Forward passes for hi: 100%"
          }
        },
        "3b1ce9b60bc14529bd73d10ab10d7e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f7191fabb094b9698b93eec1316541e",
            "max": 218,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e7ae510f5f0482481c8fcab74e8c2c6",
            "value": 218
          }
        },
        "470b782e4c704fe2a64819f23c68ec62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7447eb94fc5f4272836d0e52e06563e3",
            "placeholder": "​",
            "style": "IPY_MODEL_06f25031932f4b189325a2f194ad81a0",
            "value": " 218/218 [05:02&lt;00:00,  1.30s/it]"
          }
        },
        "77e0baf0ffb34c2bb5902ea63a1c91b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e99c549e2f85402fb8335a2793ba55c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0fa37d409a94466a7f180593a249134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f7191fabb094b9698b93eec1316541e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7ae510f5f0482481c8fcab74e8c2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7447eb94fc5f4272836d0e52e06563e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06f25031932f4b189325a2f194ad81a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1933134d2c43599cd38632b8c2bc7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f06d901b8bac412f95bb7c1516a9fbf1",
              "IPY_MODEL_aeb22175bb4942de9b814846e5b3fa33",
              "IPY_MODEL_8c2ff5a7060c424e9fee404a80f74764"
            ],
            "layout": "IPY_MODEL_20068b8943d04737a75474b6b0079465"
          }
        },
        "f06d901b8bac412f95bb7c1516a9fbf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe2cb0554fc1432c9d3ec530a02af8bb",
            "placeholder": "​",
            "style": "IPY_MODEL_2fd626c964c74725b723bb0b44d7d64b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "aeb22175bb4942de9b814846e5b3fa33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e1e628bb17248a5baa8a642fd587a63",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_727b0bf015784c00a6830903758fb2ed",
            "value": 2
          }
        },
        "8c2ff5a7060c424e9fee404a80f74764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60df747d75da40b89fc41adaed7df8ab",
            "placeholder": "​",
            "style": "IPY_MODEL_c413610a26e540289118e87e97064cb4",
            "value": " 2/2 [00:17&lt;00:00,  8.06s/it]"
          }
        },
        "20068b8943d04737a75474b6b0079465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe2cb0554fc1432c9d3ec530a02af8bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fd626c964c74725b723bb0b44d7d64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e1e628bb17248a5baa8a642fd587a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "727b0bf015784c00a6830903758fb2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60df747d75da40b89fc41adaed7df8ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c413610a26e540289118e87e97064cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a10b46010ca142a780a8d9de2e4ac4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_124b9561334540c1b768dea6d7e9004e",
              "IPY_MODEL_f47a533f9ee74567bb24b5d91a643a1f",
              "IPY_MODEL_8a5163039e5c4c0cbfdd1d997280f6b9"
            ],
            "layout": "IPY_MODEL_4b44dae176f744bbae7c62dc5c2232b1"
          }
        },
        "124b9561334540c1b768dea6d7e9004e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e117d1f53fe04d34b6152af2e4e2b53b",
            "placeholder": "​",
            "style": "IPY_MODEL_d13e49e5951c4343b2fc50ceb0672e3d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "f47a533f9ee74567bb24b5d91a643a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11f920357cbb4727bc473de9e9c2b28d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa339f2a5ac049e7891d19117879eff3",
            "value": 2
          }
        },
        "8a5163039e5c4c0cbfdd1d997280f6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afeb06c3b9de46a69ef0984adbd4f576",
            "placeholder": "​",
            "style": "IPY_MODEL_5abf158dfe5742d7abaaf48ced507136",
            "value": " 2/2 [00:34&lt;00:00, 15.63s/it]"
          }
        },
        "4b44dae176f744bbae7c62dc5c2232b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e117d1f53fe04d34b6152af2e4e2b53b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d13e49e5951c4343b2fc50ceb0672e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11f920357cbb4727bc473de9e9c2b28d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa339f2a5ac049e7891d19117879eff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afeb06c3b9de46a69ef0984adbd4f576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5abf158dfe5742d7abaaf48ced507136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}